{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b802ec-5bc9-4a7b-8d43-4bf1dc14201d",
   "metadata": {},
   "source": [
    "# 수정사항\n",
    "- 데이터 전처리과정에서 룩백기간을 조정\n",
    "- 블락조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e097566-30f2-4f57-b3a2-2ae3b7d02005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 14:41:10.698193: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-24 14:41:10.800693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-24 14:41:10.800714: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-24 14:41:11.304156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-24 14:41:11.304275: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-24 14:41:11.304286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c74fd4-9d10-4b7d-9c83-4da3c7f1871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "target_X= pd.read_csv(\"../data/solor_train_input_5.csv\").iloc[:,(1+24*0):].values\n",
    "target_y =pd.read_csv(\"../data/solor_train_output_5.csv\").iloc[:,1:].values\n",
    "test_X= pd.read_csv(\"../data/solor_val_input_5.csv\").iloc[:,(1+24*0):].values\n",
    "test_y =pd.read_csv(\"../data/solor_val_output_5.csv\").iloc[:,1:].values\n",
    "X_train=target_X\n",
    "y_train=target_y\n",
    "\n",
    "backcast_length = X_train.shape[1]\n",
    "forecast_length = y_train.shape[1]\n",
    "\n",
    "backcast_length,forecast_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bd839-0f9e-49d3-96a8-f1fe23500d97",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117869af-8623-4129-aa35-bcc7ee3da674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1],y_train.shape[1],1,1,128\n",
    "\n",
    "#################################################################################\n",
    "# nbeats + I모델 생성 함수\n",
    "def bulid_model(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK)\n",
    "                   ,nb_blocks_per_stack=1, thetas_dim=(1,2,4,4),\n",
    "                   share_weights_in_stack=True, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + G모델 생성 함수    \n",
    "def bulid_model_G(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.GENERIC_BLOCK,NBeatsKeras.GENERIC_BLOCK)\n",
    "                   ,nb_blocks_per_stack=5, thetas_dim=(2,4),\n",
    "                   share_weights_in_stack=False, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models_G(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model_G(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        position = np.arange(max_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "        pe = pe[np.newaxis, ...]\n",
    "\n",
    "        self.pe = tf.constant(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x + self.pe[:, :tf.shape(x)[1], :]\n",
    "        return self.dropout(x)\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "def create_model(fn,d_model, nlayers, nhead, dropout, iw, ow,lr):\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(pretrained_output_reshaped)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "    \n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "    \n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "    \n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    target_model = Model(inputs=inputs, outputs=outputs)\n",
    "    target_model.compile(optimizer=optimizer, loss=fn)\n",
    "    \n",
    "    return target_model\n",
    "#################################################################################\n",
    "# 예측\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4c593-18a3-4fa1-be2e-8894dc7d453f",
   "metadata": {},
   "source": [
    "# 모형적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f13c2f-9812-460b-9269-22aa352bfc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 14:41:46.279096: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-24 14:41:46.279131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-08-24 14:41:46.279622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 1.1739 - val_loss: 0.7406\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8726 - val_loss: 0.7156\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8105 - val_loss: 0.7157\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7922 - val_loss: 0.6713\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7760 - val_loss: 0.6436\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7449 - val_loss: 0.6453\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7242 - val_loss: 0.6281\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7170 - val_loss: 0.6393\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6994 - val_loss: 0.6453\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6942 - val_loss: 0.6598\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6904 - val_loss: 0.6630\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6745 - val_loss: 0.6221\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6651 - val_loss: 0.6386\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6362 - val_loss: 0.6412\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.6584\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6495\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6141 - val_loss: 0.6912\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5982 - val_loss: 0.6951\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5911 - val_loss: 0.6677\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5858 - val_loss: 0.6864\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.6692\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5437 - val_loss: 0.6506\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.2933 - val_loss: 0.7894\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8803 - val_loss: 0.7038\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8253 - val_loss: 0.6876\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7949 - val_loss: 0.6721\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7695 - val_loss: 0.6778\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7609 - val_loss: 0.6718\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7444 - val_loss: 0.6673\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7248 - val_loss: 0.6772\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7161 - val_loss: 0.6691\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7061 - val_loss: 0.6511\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6909 - val_loss: 0.6315\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6739 - val_loss: 0.6347\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6633 - val_loss: 0.6978\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6613 - val_loss: 0.6422\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 0.6476\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 0.6627\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.6868\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6665\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6780\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5929 - val_loss: 0.6407\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5528 - val_loss: 0.6695\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.2775 - val_loss: 0.7822\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8857 - val_loss: 0.7325\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8319 - val_loss: 0.6924\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7972 - val_loss: 0.6846\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7714 - val_loss: 0.6723\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7494 - val_loss: 0.6800\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7227 - val_loss: 0.6940\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7203 - val_loss: 0.6764\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7116 - val_loss: 0.6871\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7061 - val_loss: 0.6643\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6998 - val_loss: 0.6420\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6761 - val_loss: 0.6324\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6561 - val_loss: 0.6452\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6417 - val_loss: 0.6824\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6390 - val_loss: 0.6958\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.6573\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6605\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5872 - val_loss: 0.6699\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 0.6530\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5818 - val_loss: 0.6920\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 0.6804\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.6749\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.2644 - val_loss: 0.7632\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8803 - val_loss: 0.7194\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8198 - val_loss: 0.6781\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7920 - val_loss: 0.6934\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7679 - val_loss: 0.6676\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7556 - val_loss: 0.7219\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7446 - val_loss: 0.6656\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.6497\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7140 - val_loss: 0.6634\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7062 - val_loss: 0.6564\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6884 - val_loss: 0.6801\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6705 - val_loss: 0.6367\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6572 - val_loss: 0.6411\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6407 - val_loss: 0.6647\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6415 - val_loss: 0.6880\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.6805\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6220 - val_loss: 0.6833\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5957 - val_loss: 0.6860\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.7079\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5756 - val_loss: 0.6831\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5731 - val_loss: 0.6824\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5575 - val_loss: 0.6581\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.3376 - val_loss: 0.8674\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8783 - val_loss: 0.7300\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8105 - val_loss: 0.6864\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7782 - val_loss: 0.6745\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7707 - val_loss: 0.6912\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7459 - val_loss: 0.6794\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7325 - val_loss: 0.6672\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7259 - val_loss: 0.6508\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7083 - val_loss: 0.6968\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7321 - val_loss: 0.6533\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6823 - val_loss: 0.6720\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6758 - val_loss: 0.6560\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6531 - val_loss: 0.6498\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6455 - val_loss: 0.6895\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 0.6556\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6339 - val_loss: 0.6849\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6215 - val_loss: 0.6834\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5996 - val_loss: 0.6923\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5701 - val_loss: 0.6848\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5541 - val_loss: 0.6749\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5689 - val_loss: 0.6773\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.6838\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5164 - val_loss: 0.6950\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.1992 - val_loss: 0.7780\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8615 - val_loss: 0.7051\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8030 - val_loss: 0.6893\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7880 - val_loss: 0.6953\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7622 - val_loss: 0.6464\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7435 - val_loss: 0.6741\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7231 - val_loss: 0.6652\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7167 - val_loss: 0.6565\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7066 - val_loss: 0.6354\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6869 - val_loss: 0.6315\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6706 - val_loss: 0.6435\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6646 - val_loss: 0.6660\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6552 - val_loss: 0.6281\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.6684\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 0.6558\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6785\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5897 - val_loss: 0.6435\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5786 - val_loss: 0.6601\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5562 - val_loss: 0.6658\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 0.6610\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 0.6699\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 0.7009\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 0.6524\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.3066 - val_loss: 0.8245\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8697 - val_loss: 0.7069\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8227 - val_loss: 0.6744\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7869 - val_loss: 0.6819\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7813 - val_loss: 0.7302\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7757 - val_loss: 0.7069\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7315 - val_loss: 0.6696\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7165 - val_loss: 0.6479\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7056 - val_loss: 0.6755\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6870 - val_loss: 0.6768\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6945 - val_loss: 0.6758\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6871 - val_loss: 0.6621\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6630 - val_loss: 0.6299\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6484 - val_loss: 0.6656\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6349 - val_loss: 0.6568\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.6893\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 0.6619\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6233 - val_loss: 0.6572\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5924 - val_loss: 0.6932\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.7204\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 0.6948\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5696 - val_loss: 0.6789\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 0.6748\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.2348 - val_loss: 0.7801\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8785 - val_loss: 0.7146\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8052 - val_loss: 0.6666\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7740 - val_loss: 0.6666\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7614 - val_loss: 0.6556\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7626 - val_loss: 0.6811\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7256 - val_loss: 0.6583\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7138 - val_loss: 0.6716\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7035 - val_loss: 0.6673\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6735 - val_loss: 0.6477\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6564 - val_loss: 0.6839\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6604 - val_loss: 0.6462\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6471 - val_loss: 0.6379\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.6521\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 0.6577\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.6744\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.6771\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5675 - val_loss: 0.7099\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5586 - val_loss: 0.6745\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 0.7039\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 0.7202\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5180 - val_loss: 0.7132\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 0.6685\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.1922 - val_loss: 0.7749\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8643 - val_loss: 0.7296\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8105 - val_loss: 0.6677\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7718 - val_loss: 0.7433\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7810 - val_loss: 0.6727\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7444 - val_loss: 0.6723\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7457 - val_loss: 0.6342\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7086 - val_loss: 0.6524\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7061 - val_loss: 0.6504\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7013 - val_loss: 0.6717\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6862 - val_loss: 0.6561\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6614 - val_loss: 0.6732\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6667 - val_loss: 0.6573\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6564 - val_loss: 0.6636\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6268 - val_loss: 0.6595\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6364 - val_loss: 0.6549\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6781\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 1.2510 - val_loss: 0.7947\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8617 - val_loss: 0.7497\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8160 - val_loss: 0.7048\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7971 - val_loss: 0.6820\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7622 - val_loss: 0.7179\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7452 - val_loss: 0.6610\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7198 - val_loss: 0.6742\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7161 - val_loss: 0.6626\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7107 - val_loss: 0.6322\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6974 - val_loss: 0.7175\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6858 - val_loss: 0.6468\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6799 - val_loss: 0.6653\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6687 - val_loss: 0.7402\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6638 - val_loss: 0.6878\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6591 - val_loss: 0.6539\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6363 - val_loss: 0.6536\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6219 - val_loss: 0.6685\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6441 - val_loss: 0.6694\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6998\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 117854576.0000 - val_loss: 35946248.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 27466242.0000 - val_loss: 21027956.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 17712278.0000 - val_loss: 15993137.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 15026762.0000 - val_loss: 10837798.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 10041488.0000 - val_loss: 10720162.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9321037.0000 - val_loss: 8410084.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7136268.5000 - val_loss: 8048561.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5829453.0000 - val_loss: 4794810.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5391520.5000 - val_loss: 5323613.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5014087.0000 - val_loss: 6068083.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4315417.0000 - val_loss: 5783682.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4062225.2500 - val_loss: 4406043.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3113866.5000 - val_loss: 3440242.7500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2895768.2500 - val_loss: 2735212.7500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2930789.7500 - val_loss: 3079133.2500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2512560.7500 - val_loss: 2417106.7500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2900200.5000 - val_loss: 2214218.5000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2266076.2500 - val_loss: 1814467.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2341487.7500 - val_loss: 3687193.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2327173.2500 - val_loss: 2054854.1250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2322817.7500 - val_loss: 2686370.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2061808.7500 - val_loss: 1761385.5000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1875242.1250 - val_loss: 1621482.8750\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1527141.7500 - val_loss: 1651503.8750\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1628810.1250 - val_loss: 2918549.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1471646.8750 - val_loss: 1201916.7500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1873329.6250 - val_loss: 1603071.5000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1730640.3750 - val_loss: 1783585.6250\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1153011.1250 - val_loss: 1249050.8750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1214858.6250 - val_loss: 1076080.5000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1213964.6250 - val_loss: 1277770.8750\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1516646.7500 - val_loss: 3800928.7500\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1394843.1250 - val_loss: 1240290.3750\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1316167.0000 - val_loss: 1419363.2500\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1111863.8750 - val_loss: 1480917.3750\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1139903.5000 - val_loss: 1344515.3750\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1229075.0000 - val_loss: 1572746.1250\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1140810.1250 - val_loss: 799749.1250\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1115594.5000 - val_loss: 1617320.8750\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1259452.6250 - val_loss: 1616912.7500\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1185819.8750 - val_loss: 1305292.2500\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1200946.5000 - val_loss: 765648.8125\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 803763.6250 - val_loss: 875861.2500\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 952975.3750 - val_loss: 923919.8750\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1071658.7500 - val_loss: 1195955.1250\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 989762.6875 - val_loss: 1594887.8750\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1472630.7500 - val_loss: 1172667.1250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 962519.5625 - val_loss: 1080046.0000\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 758884.0625 - val_loss: 738006.5625\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 958490.9375 - val_loss: 863239.8125\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 763923.3750 - val_loss: 1084271.1250\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 695704.6250 - val_loss: 684682.8125\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 879389.3750 - val_loss: 910000.1875\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 817629.1250 - val_loss: 861272.2500\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 671990.9375 - val_loss: 769981.5000\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 690246.3750 - val_loss: 581531.0000\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 733974.2500 - val_loss: 685642.8750\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 711052.5625 - val_loss: 873026.6250\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 857280.3125 - val_loss: 711902.2500\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 621949.8125 - val_loss: 1179130.8750\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 815280.9375 - val_loss: 737939.9375\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 755163.3125 - val_loss: 637614.2500\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 567294.7500 - val_loss: 564857.1875\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 552576.6875 - val_loss: 689503.8750\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 647856.6250 - val_loss: 535914.0625\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 459346.8125 - val_loss: 488252.4688\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 530262.8750 - val_loss: 516905.5000\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 583188.5625 - val_loss: 1187852.1250\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 585026.8125 - val_loss: 888806.0000\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 652720.1250 - val_loss: 672051.4375\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 469445.3125 - val_loss: 558899.6250\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 402098.5625 - val_loss: 485286.4688\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 534303.5625 - val_loss: 449483.2500\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 703563.8750 - val_loss: 1582545.3750\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 970000.0625 - val_loss: 439105.2188\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 343708.9375 - val_loss: 347160.3750\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 341621.6250 - val_loss: 406032.8125\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 368488.5000 - val_loss: 954191.7500\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 420150.3750 - val_loss: 1277010.5000\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 456631.9688 - val_loss: 584780.0000\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 526383.8750 - val_loss: 632106.3750\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 351354.0000 - val_loss: 371985.7500\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 312465.1562 - val_loss: 229645.1875\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 298120.6562 - val_loss: 195405.2344\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 241350.1250 - val_loss: 218985.5156\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 317896.0625 - val_loss: 360691.8750\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 370782.9375 - val_loss: 261245.2969\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 211994.3281 - val_loss: 221286.6250\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 220919.0469 - val_loss: 88438.7188\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 231646.9062 - val_loss: 109184.8594\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 217691.0625 - val_loss: 687285.4375\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 307281.5625 - val_loss: 88725.0391\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 250026.3281 - val_loss: 146024.7656\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 248201.0312 - val_loss: 337753.0938\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 237471.2031 - val_loss: 340194.5000\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 246383.6719 - val_loss: 221623.5156\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 102116.3750 - val_loss: 59328.2188\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 103223.1562 - val_loss: 125415.8516\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 172570.3438 - val_loss: 174605.4531\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 135857.0938 - val_loss: 178580.3750\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 127191872.0000 - val_loss: 48818296.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 39201680.0000 - val_loss: 34090736.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 25797944.0000 - val_loss: 26510578.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 18672012.0000 - val_loss: 19324856.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 14304940.0000 - val_loss: 15542816.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 12753388.0000 - val_loss: 15123557.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9914299.0000 - val_loss: 10406231.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8794769.0000 - val_loss: 11419878.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8236502.5000 - val_loss: 9976009.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7491879.0000 - val_loss: 7894574.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6326545.5000 - val_loss: 6214129.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5027410.5000 - val_loss: 5502854.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5393231.5000 - val_loss: 6525960.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4575058.5000 - val_loss: 5105553.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4253949.5000 - val_loss: 7724705.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4171856.2500 - val_loss: 4979390.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3681480.7500 - val_loss: 4401267.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3250142.2500 - val_loss: 3696632.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2975295.7500 - val_loss: 3678678.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3037099.0000 - val_loss: 3034505.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3046019.2500 - val_loss: 3513314.5000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2362520.7500 - val_loss: 3116476.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2359777.2500 - val_loss: 4428474.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2189863.7500 - val_loss: 2652511.5000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1980672.2500 - val_loss: 2476818.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1857772.1250 - val_loss: 1920235.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2123185.7500 - val_loss: 3965135.5000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1775662.0000 - val_loss: 2264242.7500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1550140.0000 - val_loss: 1707711.1250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1454875.6250 - val_loss: 2888708.5000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1780268.5000 - val_loss: 1830142.5000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1346319.2500 - val_loss: 1585442.3750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1272956.1250 - val_loss: 1542487.5000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1564461.0000 - val_loss: 2123240.5000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1582292.5000 - val_loss: 1446622.0000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1075598.5000 - val_loss: 1147630.2500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 896215.3750 - val_loss: 1575525.2500\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1065917.0000 - val_loss: 925338.0625\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 869585.0000 - val_loss: 1160031.7500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 939307.7500 - val_loss: 768264.0625\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 892081.0625 - val_loss: 1200534.1250\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 907119.1250 - val_loss: 1010407.8125\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 862956.1875 - val_loss: 1009291.3750\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 757430.5000 - val_loss: 676911.6250\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 502657.8125 - val_loss: 591554.8750\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 404693.8438 - val_loss: 426606.7188\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 519631.0000 - val_loss: 315064.6875\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 382574.0000 - val_loss: 391751.5625\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 359026.2500 - val_loss: 246851.3125\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 254366.7812 - val_loss: 593170.0000\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 363401.2812 - val_loss: 490440.3438\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 281717.0938 - val_loss: 278621.3125\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 303859.2188 - val_loss: 343361.7500\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 317359.3438 - val_loss: 223804.6562\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 239458.1250 - val_loss: 240082.4219\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 251349.9844 - val_loss: 326307.8750\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 207976.1719 - val_loss: 284654.6250\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 211307.7031 - val_loss: 212064.2812\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 211182.5156 - val_loss: 214213.7031\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 302749.3750 - val_loss: 329741.4375\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 205503.4375 - val_loss: 151393.8281\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 244938.7188 - val_loss: 200882.1094\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195524.3125 - val_loss: 185857.7656\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 199326.9219 - val_loss: 215254.0469\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 172782.0469 - val_loss: 241520.2500\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 202425.3438 - val_loss: 248574.4531\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 251955.6250 - val_loss: 297608.2812\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 185185.5312 - val_loss: 172197.2969\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 308015.7188 - val_loss: 191269.5938\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 151264.3281 - val_loss: 225692.2812\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 146237.7500 - val_loss: 156528.8281\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 115579304.0000 - val_loss: 43037424.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 36091120.0000 - val_loss: 27644626.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 23178602.0000 - val_loss: 18309078.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 16072266.0000 - val_loss: 15150513.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 12794399.0000 - val_loss: 14220386.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 14621735.0000 - val_loss: 18194244.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9548070.0000 - val_loss: 8153695.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8042018.5000 - val_loss: 9805033.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6742650.0000 - val_loss: 9301440.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8364816.0000 - val_loss: 11164860.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6398548.0000 - val_loss: 9640001.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5486330.5000 - val_loss: 5219875.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4235623.5000 - val_loss: 4944925.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4057316.0000 - val_loss: 3813415.7500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3317783.2500 - val_loss: 5289998.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3699276.7500 - val_loss: 3208891.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3109017.7500 - val_loss: 3088040.5000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3961001.7500 - val_loss: 4836373.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3510239.5000 - val_loss: 2760046.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2850419.5000 - val_loss: 5441001.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2847393.2500 - val_loss: 2670368.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2537863.7500 - val_loss: 3671503.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3011341.5000 - val_loss: 4950172.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2537154.2500 - val_loss: 3980040.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2481473.5000 - val_loss: 3846113.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2230023.2500 - val_loss: 2917639.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2070178.7500 - val_loss: 3783303.0000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2187844.0000 - val_loss: 5599860.0000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2323173.0000 - val_loss: 2539669.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1790380.2500 - val_loss: 2719962.5000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1694773.6250 - val_loss: 2583727.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2191308.5000 - val_loss: 1795031.1250\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1627200.8750 - val_loss: 2636605.2500\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1587049.1250 - val_loss: 1662385.8750\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1795319.1250 - val_loss: 2423795.2500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1504924.3750 - val_loss: 1589734.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1669591.0000 - val_loss: 5027111.5000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1843950.6250 - val_loss: 1263006.7500\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1701384.0000 - val_loss: 1339366.5000\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1293753.3750 - val_loss: 1947897.3750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1323397.1250 - val_loss: 2036602.7500\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1193383.2500 - val_loss: 1326748.7500\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1175012.0000 - val_loss: 1578935.0000\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1464556.5000 - val_loss: 1139344.6250\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1242769.1250 - val_loss: 1241523.8750\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1294599.7500 - val_loss: 1894108.5000\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1274182.5000 - val_loss: 1080285.8750\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1438837.1250 - val_loss: 1483616.5000\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1300856.0000 - val_loss: 3335735.5000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1816343.5000 - val_loss: 1145360.1250\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 933648.6250 - val_loss: 1070664.7500\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 889362.9375 - val_loss: 968865.7500\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1015442.3750 - val_loss: 1070637.2500\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 903074.5000 - val_loss: 991962.2500\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1224473.3750 - val_loss: 2078717.7500\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1535288.3750 - val_loss: 1364143.3750\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1222999.8750 - val_loss: 1695239.3750\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1058792.3750 - val_loss: 1218185.1250\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1341584.0000 - val_loss: 1946611.8750\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1235930.2500 - val_loss: 943732.4375\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 802272.0625 - val_loss: 775807.5000\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 863418.1875 - val_loss: 1359031.6250\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 933345.0000 - val_loss: 757911.1250\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 751698.4375 - val_loss: 1485826.7500\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 944597.6875 - val_loss: 879233.3750\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 866278.5625 - val_loss: 1045025.8750\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 853286.2500 - val_loss: 1283534.1250\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 681506.3125 - val_loss: 627676.0000\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 606314.3750 - val_loss: 828014.7500\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 652479.1875 - val_loss: 813012.0000\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 622867.1250 - val_loss: 693510.3750\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 589242.2500 - val_loss: 601652.0000\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 498109.6875 - val_loss: 444736.9062\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 399595.1250 - val_loss: 714521.8125\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 618643.9375 - val_loss: 607980.1875\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 468265.8125 - val_loss: 868895.6250\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 524921.0000 - val_loss: 519429.9062\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 342120.6875 - val_loss: 929446.6250\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 346558.8750 - val_loss: 310696.7188\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 243651.8438 - val_loss: 209941.0312\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 289484.9062 - val_loss: 218913.6250\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 180207.4688 - val_loss: 243745.2188\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 169230.6875 - val_loss: 289504.5625\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 185793.1406 - val_loss: 144950.3906\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 141711.1562 - val_loss: 242035.4531\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 143859.6406 - val_loss: 88361.8047\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127312.2734 - val_loss: 145535.1875\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133878.7656 - val_loss: 164559.6562\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 119921.8984 - val_loss: 142431.3594\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 144171.8594 - val_loss: 155263.7344\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136369.5312 - val_loss: 184169.1875\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125966.7656 - val_loss: 176529.7031\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 172369.5156 - val_loss: 174288.2344\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 160111.8594 - val_loss: 157800.7656\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 138415.6250 - val_loss: 244025.4844\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 138012.5000 - val_loss: 54413.1680\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 102659.3281 - val_loss: 262770.5000\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 93015.2812 - val_loss: 110806.5547\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 96311.2500 - val_loss: 303249.3438\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 108364.0469 - val_loss: 68203.6328\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 105184184.0000 - val_loss: 46100208.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 32658272.0000 - val_loss: 33981156.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 22045244.0000 - val_loss: 18969558.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 15229164.0000 - val_loss: 15947645.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13352976.0000 - val_loss: 13736627.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 10401039.0000 - val_loss: 11195984.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8879579.0000 - val_loss: 10028559.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8490451.0000 - val_loss: 7541392.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6973491.5000 - val_loss: 7033403.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6128179.5000 - val_loss: 6002086.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5969273.5000 - val_loss: 6104286.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5408405.5000 - val_loss: 4964548.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5297247.0000 - val_loss: 7467957.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4755301.0000 - val_loss: 4275266.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4486229.0000 - val_loss: 4615478.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4304025.5000 - val_loss: 4589751.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4250594.0000 - val_loss: 9381054.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4551420.5000 - val_loss: 5404974.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3647463.0000 - val_loss: 3420440.2500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3287066.2500 - val_loss: 3505361.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2846591.2500 - val_loss: 4621836.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2849525.7500 - val_loss: 2840496.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2744092.0000 - val_loss: 2931076.7500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3099581.2500 - val_loss: 2391842.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2801393.5000 - val_loss: 2774181.7500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2101474.0000 - val_loss: 3147121.7500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2326089.5000 - val_loss: 3320882.5000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2393328.2500 - val_loss: 3155865.7500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1990651.3750 - val_loss: 3571830.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2060711.0000 - val_loss: 2029468.2500\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2011864.7500 - val_loss: 1910082.2500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2130269.0000 - val_loss: 1726082.8750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1710499.6250 - val_loss: 1615763.2500\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1747800.1250 - val_loss: 1727201.1250\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1480412.2500 - val_loss: 1788692.0000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1589077.7500 - val_loss: 1566504.5000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1917972.8750 - val_loss: 1453427.7500\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1347448.8750 - val_loss: 1490812.3750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1329534.5000 - val_loss: 2207737.0000\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1694335.5000 - val_loss: 1520062.0000\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1265023.6250 - val_loss: 1758971.7500\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1454513.2500 - val_loss: 1988725.0000\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1573335.7500 - val_loss: 1249847.0000\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1517683.0000 - val_loss: 1388925.3750\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1153348.0000 - val_loss: 1872461.0000\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1234741.7500 - val_loss: 1466423.8750\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1329023.8750 - val_loss: 1304851.6250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1495269.7500 - val_loss: 1947804.2500\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1135540.2500 - val_loss: 972789.0625\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1217201.6250 - val_loss: 1467942.8750\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1054010.0000 - val_loss: 2063773.3750\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1383606.0000 - val_loss: 1437472.3750\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1132175.7500 - val_loss: 1008206.8125\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 968194.1875 - val_loss: 1021605.5000\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1087737.0000 - val_loss: 1378176.7500\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 962294.6875 - val_loss: 1531232.7500\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 767041.5000 - val_loss: 770690.8750\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 908838.6250 - val_loss: 1015456.3125\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 727238.3750 - val_loss: 836732.3750\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 903509.0000 - val_loss: 775899.4375\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 927040.6875 - val_loss: 889694.3750\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 688136.6875 - val_loss: 1270519.1250\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 616640.1250 - val_loss: 477696.0000\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 478059.6875 - val_loss: 582771.8125\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 420157.0312 - val_loss: 504988.5938\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 367693.1875 - val_loss: 341224.1875\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 364524.2500 - val_loss: 370540.1250\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 403957.8750 - val_loss: 339188.8750\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 282277.2188 - val_loss: 344777.0625\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 354383.9688 - val_loss: 278429.7812\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 312578.0938 - val_loss: 361287.1562\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 284963.2812 - val_loss: 315358.3750\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 211418.2812 - val_loss: 230425.0000\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 194298.1562 - val_loss: 309792.3125\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 199137.8125 - val_loss: 247103.8906\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 222023.3594 - val_loss: 264870.0625\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 268674.3125 - val_loss: 261005.9375\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 239254.6719 - val_loss: 258655.7812\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 287538.4375 - val_loss: 235493.4844\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 244544.1094 - val_loss: 228978.1875\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 189008.6719 - val_loss: 239607.9375\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 173804.4375 - val_loss: 235659.6094\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 201738.1406 - val_loss: 259345.7031\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 224564.0938 - val_loss: 271694.4062\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 256332.4844 - val_loss: 199974.0625\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 141136.6562 - val_loss: 251460.1406\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 161496.4219 - val_loss: 130083.5859\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 168997.8750 - val_loss: 248352.0781\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 155499.4688 - val_loss: 292272.2188\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 158130.6875 - val_loss: 177812.1875\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 150608.9062 - val_loss: 178880.4844\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 140354.3594 - val_loss: 254740.8594\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 163321.0312 - val_loss: 105096.3281\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 162140.1250 - val_loss: 111341.5703\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121889.6094 - val_loss: 202068.2656\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 166837.5156 - val_loss: 110197.0859\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 112871.2344 - val_loss: 61547.2344\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 110950.0234 - val_loss: 140627.7500\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 111273.5938 - val_loss: 107069.3047\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 110790.8906 - val_loss: 93957.5391\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 97193408.0000 - val_loss: 40666876.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 27830556.0000 - val_loss: 24751176.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 20165524.0000 - val_loss: 14459387.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13963702.0000 - val_loss: 10807684.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 11501222.0000 - val_loss: 10194615.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8068305.0000 - val_loss: 7250128.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6952568.0000 - val_loss: 8495863.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6542388.5000 - val_loss: 6109927.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6538856.0000 - val_loss: 5337888.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5096886.0000 - val_loss: 4109804.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4397729.5000 - val_loss: 4426948.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3826446.2500 - val_loss: 4467242.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3267202.2500 - val_loss: 3549122.2500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3263730.7500 - val_loss: 3472354.7500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2828618.2500 - val_loss: 3749545.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3062503.0000 - val_loss: 3161727.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3079071.5000 - val_loss: 3166539.5000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2803081.0000 - val_loss: 2894315.2500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2291286.5000 - val_loss: 3183925.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2180301.7500 - val_loss: 3140545.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2227409.2500 - val_loss: 2282837.5000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1698957.5000 - val_loss: 2566741.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2106841.2500 - val_loss: 2333927.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1723990.1250 - val_loss: 2810848.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2061459.2500 - val_loss: 2173793.7500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1769371.1250 - val_loss: 2356950.2500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1567381.8750 - val_loss: 1721124.6250\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1389409.8750 - val_loss: 2127012.5000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1529650.5000 - val_loss: 2384990.2500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1464628.2500 - val_loss: 1696310.6250\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1660048.2500 - val_loss: 2341359.7500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1837240.1250 - val_loss: 1513016.1250\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1411883.7500 - val_loss: 1746020.1250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1565006.3750 - val_loss: 1409972.2500\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1250546.5000 - val_loss: 1187629.0000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1152422.1250 - val_loss: 1220722.5000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1223900.8750 - val_loss: 2011631.5000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1081685.8750 - val_loss: 1560745.8750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1036535.5000 - val_loss: 1094869.1250\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1002964.8125 - val_loss: 1343668.6250\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1330595.8750 - val_loss: 1794361.2500\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1148561.0000 - val_loss: 1007989.3125\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 914006.7500 - val_loss: 1880215.1250\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1179227.7500 - val_loss: 1187573.7500\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1252494.0000 - val_loss: 936275.6250\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1042235.6875 - val_loss: 1328138.3750\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 814238.5625 - val_loss: 891874.6875\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 930921.4375 - val_loss: 1471324.1250\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 827918.1250 - val_loss: 886261.8125\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1028664.3750 - val_loss: 1023847.3125\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 941159.0625 - val_loss: 1436127.6250\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 899422.5625 - val_loss: 1463974.2500\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 904917.3125 - val_loss: 852572.1875\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 736331.5625 - val_loss: 732319.1875\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 714643.3750 - val_loss: 1452685.3750\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 976197.0625 - val_loss: 2440463.5000\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1107284.8750 - val_loss: 950609.6250\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 947485.8125 - val_loss: 1229750.3750\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 720868.6250 - val_loss: 701580.4375\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 888240.8750 - val_loss: 797782.6875\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 629676.7500 - val_loss: 725475.8125\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 567916.4375 - val_loss: 1003378.1875\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 669192.5625 - val_loss: 723622.3125\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 567727.4375 - val_loss: 834371.5000\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 508670.0000 - val_loss: 489950.5625\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 523687.4062 - val_loss: 540729.3125\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 438221.3125 - val_loss: 516387.0312\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 387171.7812 - val_loss: 330850.9688\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 551547.9375 - val_loss: 610422.3750\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 334869.0000 - val_loss: 422877.4375\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 448165.0312 - val_loss: 432239.0000\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 480185.3438 - val_loss: 635851.4375\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 332668.3125 - val_loss: 359193.1562\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 306710.1562 - val_loss: 261172.7969\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 249890.3750 - val_loss: 357812.3125\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 385256.7188 - val_loss: 255223.7812\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 225504.3438 - val_loss: 335687.7188\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 224730.4062 - val_loss: 354567.4375\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 223904.0156 - val_loss: 224590.6562\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 203421.0781 - val_loss: 351361.7812\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 232101.8125 - val_loss: 466143.2812\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 217841.6875 - val_loss: 172485.7031\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 275190.6562 - val_loss: 194109.4688\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 161144.0938 - val_loss: 181347.4688\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 167998.9375 - val_loss: 169671.4219\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 196158.3594 - val_loss: 121972.3281\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 163269.9688 - val_loss: 273217.8125\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 191991.9219 - val_loss: 194954.2969\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 163651.0938 - val_loss: 250385.5781\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 152466.6562 - val_loss: 105971.8984\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123731.9844 - val_loss: 113492.6953\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137171.6875 - val_loss: 126229.6250\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136749.8906 - val_loss: 109285.7891\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 135775.6250 - val_loss: 138078.5938\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132324.3125 - val_loss: 145987.0000\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131685.3594 - val_loss: 121202.7031\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 118925.7578 - val_loss: 115090.9219\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195392.5469 - val_loss: 179564.4062\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136166.7344 - val_loss: 281074.0312\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 175793.7500 - val_loss: 93445.1484\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 88125968.0000 - val_loss: 45788520.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 31325436.0000 - val_loss: 24579622.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 19642314.0000 - val_loss: 17730728.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 15385077.0000 - val_loss: 16747140.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 12188715.0000 - val_loss: 11097827.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 10413099.0000 - val_loss: 10178397.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8474133.0000 - val_loss: 9061675.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7355234.0000 - val_loss: 7873249.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7864560.0000 - val_loss: 7242908.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6597076.0000 - val_loss: 8671446.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5232506.5000 - val_loss: 5383279.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4705924.0000 - val_loss: 3926553.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4763007.0000 - val_loss: 4929047.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3873839.5000 - val_loss: 5023978.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4246519.5000 - val_loss: 5852497.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3816446.7500 - val_loss: 3410749.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3181282.7500 - val_loss: 5598555.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3520497.5000 - val_loss: 3772425.2500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2605977.5000 - val_loss: 3311299.2500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2973345.2500 - val_loss: 3741334.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2274989.7500 - val_loss: 2591491.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2512221.7500 - val_loss: 2895912.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2000680.1250 - val_loss: 2958046.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1999284.5000 - val_loss: 3340637.5000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2383426.7500 - val_loss: 4543496.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2457594.5000 - val_loss: 2056591.0000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1928905.7500 - val_loss: 1739270.0000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1931685.2500 - val_loss: 2160871.5000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2573393.0000 - val_loss: 3244811.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1841727.1250 - val_loss: 2502950.5000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1802154.8750 - val_loss: 1839258.1250\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1998444.2500 - val_loss: 1718645.8750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1486866.2500 - val_loss: 1320848.7500\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1653789.8750 - val_loss: 3656459.7500\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2024697.7500 - val_loss: 1812266.0000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1401330.8750 - val_loss: 1129794.6250\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1263218.0000 - val_loss: 1226701.6250\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1129142.5000 - val_loss: 1404973.3750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1190786.1250 - val_loss: 1257404.6250\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1381516.0000 - val_loss: 1291624.1250\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1058358.6250 - val_loss: 1204654.3750\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1106142.2500 - val_loss: 1510552.1250\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1253838.1250 - val_loss: 1262653.3750\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 956610.7500 - val_loss: 1139956.1250\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 992843.6250 - val_loss: 1165951.2500\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1016523.0625 - val_loss: 1176317.7500\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 114513832.0000 - val_loss: 45723904.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 33193034.0000 - val_loss: 27898524.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 23298900.0000 - val_loss: 23050084.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 19295222.0000 - val_loss: 16491891.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 14803744.0000 - val_loss: 13823477.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 12011141.0000 - val_loss: 12560068.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 10371163.0000 - val_loss: 11683272.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8930230.0000 - val_loss: 9923038.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7443849.5000 - val_loss: 10768487.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6716875.5000 - val_loss: 10039628.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7520928.5000 - val_loss: 7807525.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6202320.0000 - val_loss: 7013024.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5377210.5000 - val_loss: 6696927.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4949339.0000 - val_loss: 5499246.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4230488.5000 - val_loss: 6153771.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4510346.0000 - val_loss: 7628067.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5213232.5000 - val_loss: 4637259.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3962438.7500 - val_loss: 4426484.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3690286.5000 - val_loss: 6256983.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3015187.5000 - val_loss: 3167575.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2862594.2500 - val_loss: 5234688.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3047515.0000 - val_loss: 2738402.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2597842.0000 - val_loss: 2998841.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3083069.2500 - val_loss: 2844780.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2574101.2500 - val_loss: 2765880.5000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2384830.7500 - val_loss: 3062527.7500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2167081.2500 - val_loss: 2586411.7500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2261003.5000 - val_loss: 2282598.7500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2347347.2500 - val_loss: 2751164.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1937648.5000 - val_loss: 4491125.5000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2349848.2500 - val_loss: 2279114.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2070086.6250 - val_loss: 3438541.7500\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2084723.6250 - val_loss: 1773364.5000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2395717.2500 - val_loss: 2195290.5000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1611343.6250 - val_loss: 2073607.2500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1455199.7500 - val_loss: 2488885.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1434207.8750 - val_loss: 3238924.2500\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1578682.3750 - val_loss: 1588276.5000\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1724995.3750 - val_loss: 2592612.7500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1237523.7500 - val_loss: 1895022.3750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1165443.7500 - val_loss: 2743936.0000\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1470729.1250 - val_loss: 2731662.2500\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1691707.7500 - val_loss: 2245403.2500\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1616050.1250 - val_loss: 2157282.7500\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1521013.0000 - val_loss: 1398326.3750\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1680643.6250 - val_loss: 2059750.6250\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1318406.8750 - val_loss: 1947617.1250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1219837.0000 - val_loss: 1225448.0000\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1319256.2500 - val_loss: 1107388.5000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1536849.2500 - val_loss: 2190769.5000\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1113221.0000 - val_loss: 1639758.3750\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1093827.2500 - val_loss: 1335922.3750\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1111218.2500 - val_loss: 1287412.3750\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1219418.8750 - val_loss: 1091910.7500\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 870330.3750 - val_loss: 928574.8750\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 878345.3125 - val_loss: 1008462.8125\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 884663.3125 - val_loss: 1503617.6250\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 973394.0625 - val_loss: 1174624.3750\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 875113.2500 - val_loss: 1087432.2500\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 904165.0625 - val_loss: 1252915.3750\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 985597.4375 - val_loss: 840786.3125\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 741808.3125 - val_loss: 1109085.1250\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 902766.3125 - val_loss: 1490540.8750\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 886788.8125 - val_loss: 1282615.7500\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1057699.0000 - val_loss: 1557909.3750\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 842344.2500 - val_loss: 924177.6250\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 796189.0000 - val_loss: 939273.0625\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 762405.1250 - val_loss: 1569215.5000\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 886768.6875 - val_loss: 1530945.3750\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 849244.3750 - val_loss: 1055963.0000\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 635296.2500 - val_loss: 1109670.5000\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 97877920.0000 - val_loss: 51469452.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 36463404.0000 - val_loss: 29728514.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 24281492.0000 - val_loss: 22730684.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 18892048.0000 - val_loss: 23318502.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 17306246.0000 - val_loss: 16474336.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 11196804.0000 - val_loss: 12033996.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9405285.0000 - val_loss: 10004464.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8129417.5000 - val_loss: 9451798.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7022258.5000 - val_loss: 7940014.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6486603.5000 - val_loss: 8214254.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6141598.5000 - val_loss: 7413821.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5261431.5000 - val_loss: 7201516.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5040495.0000 - val_loss: 5559544.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5992381.0000 - val_loss: 5260704.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4486278.0000 - val_loss: 6601673.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4130957.2500 - val_loss: 5936684.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4059784.5000 - val_loss: 4353002.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3851060.7500 - val_loss: 4525087.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3627034.2500 - val_loss: 3633008.7500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3114605.0000 - val_loss: 4380839.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3097268.2500 - val_loss: 4196338.5000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3186172.2500 - val_loss: 3263406.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2853068.5000 - val_loss: 5319798.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2694244.0000 - val_loss: 2503872.2500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2257908.5000 - val_loss: 3154419.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2170382.5000 - val_loss: 2472735.7500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1912811.6250 - val_loss: 2323377.5000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1853981.0000 - val_loss: 2926309.2500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2592170.2500 - val_loss: 2759939.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1802590.5000 - val_loss: 2979051.2500\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1696693.5000 - val_loss: 2019217.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1529092.1250 - val_loss: 2079634.5000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2080785.5000 - val_loss: 1517938.6250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1369452.3750 - val_loss: 1832788.3750\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1443420.6250 - val_loss: 1498738.0000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1529117.3750 - val_loss: 1621227.7500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1525947.1250 - val_loss: 3819057.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1598907.3750 - val_loss: 2639542.5000\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1145474.0000 - val_loss: 1255594.8750\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 924044.6875 - val_loss: 1191432.1250\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1076187.2500 - val_loss: 1085230.2500\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 979382.5625 - val_loss: 1441098.5000\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 962634.6250 - val_loss: 1623703.7500\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 820443.1250 - val_loss: 1046403.7500\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 734176.2500 - val_loss: 1777194.3750\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 708807.3750 - val_loss: 788233.8750\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 732446.8125 - val_loss: 723561.1875\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 523675.5625 - val_loss: 614086.6250\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 553645.6875 - val_loss: 758900.5000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 502456.2500 - val_loss: 670026.9375\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 590745.7500 - val_loss: 795289.9375\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 616484.1875 - val_loss: 1281406.3750\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 471826.8125 - val_loss: 571603.8750\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 395601.7500 - val_loss: 510601.2188\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 474464.0000 - val_loss: 628631.7500\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 489101.9062 - val_loss: 822531.6250\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 509973.5938 - val_loss: 639550.3125\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 438871.3750 - val_loss: 447945.0625\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 498761.5625 - val_loss: 409906.2188\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 381633.5938 - val_loss: 569791.4375\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 411984.5938 - val_loss: 579731.5625\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 391523.2500 - val_loss: 363435.1250\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 293692.4062 - val_loss: 371670.9688\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 382147.8438 - val_loss: 463521.8750\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 372629.0312 - val_loss: 499300.9688\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 371175.1562 - val_loss: 356369.6250\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 330704.1875 - val_loss: 891555.4375\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 369508.0000 - val_loss: 441920.1875\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 315863.4062 - val_loss: 320414.5938\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 335633.9375 - val_loss: 407304.7188\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 288256.4062 - val_loss: 332748.2500\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 241630.8594 - val_loss: 345158.1562\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 292622.3438 - val_loss: 276763.4062\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 337740.5000 - val_loss: 452552.9062\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 370389.6875 - val_loss: 360792.0938\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 285366.1875 - val_loss: 452726.3438\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 275304.8750 - val_loss: 283823.2188\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 250436.2031 - val_loss: 285063.8125\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 252077.6250 - val_loss: 240502.5625\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 236170.9844 - val_loss: 295514.7812\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 201576.8750 - val_loss: 194792.3594\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 247145.7188 - val_loss: 198243.9375\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 198278.8750 - val_loss: 211913.3594\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 265742.2500 - val_loss: 266804.5625\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 235205.0156 - val_loss: 652688.8125\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 315072.5625 - val_loss: 295156.5625\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195720.7812 - val_loss: 247735.0312\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 178781.3438 - val_loss: 169440.5469\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 229908.8594 - val_loss: 255929.8438\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 186240.0938 - val_loss: 193679.1562\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 205835.4688 - val_loss: 331471.9688\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 231098.2656 - val_loss: 221013.7031\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 180453.9844 - val_loss: 171325.8906\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 174514.7188 - val_loss: 306076.7188\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 184133.9062 - val_loss: 255810.1719\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134866.6250 - val_loss: 279521.3438\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 144482.9375 - val_loss: 313706.8438\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 180555.5938 - val_loss: 412384.5312\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 11ms/step - loss: 98219560.0000 - val_loss: 38049580.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 28335578.0000 - val_loss: 24031704.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 17688918.0000 - val_loss: 15230286.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 12979157.0000 - val_loss: 12015439.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 10193621.0000 - val_loss: 8881511.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8539528.0000 - val_loss: 8050347.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7480333.5000 - val_loss: 7208294.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5657430.0000 - val_loss: 4555855.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4842793.0000 - val_loss: 5211476.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5295520.0000 - val_loss: 7426802.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4198540.0000 - val_loss: 6640303.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4378711.5000 - val_loss: 5471154.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3352746.2500 - val_loss: 3501352.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3292902.7500 - val_loss: 3102041.7500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2886580.7500 - val_loss: 2672478.7500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2475759.5000 - val_loss: 2628199.7500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2377657.0000 - val_loss: 2568737.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2248187.7500 - val_loss: 2624741.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2352101.2500 - val_loss: 2381898.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2449104.5000 - val_loss: 1857844.1250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1930732.7500 - val_loss: 4491184.5000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2196487.0000 - val_loss: 2044608.2500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1906689.5000 - val_loss: 1984270.7500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1927738.8750 - val_loss: 2355295.0000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2338679.7500 - val_loss: 1913521.3750\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1626897.1250 - val_loss: 3411024.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1607469.1250 - val_loss: 2937251.5000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1567587.8750 - val_loss: 1179906.0000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1314250.1250 - val_loss: 1350982.8750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1266584.8750 - val_loss: 1064860.0000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1155373.0000 - val_loss: 1472114.3750\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1359300.1250 - val_loss: 1529168.5000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1402924.5000 - val_loss: 969414.8125\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1049589.8750 - val_loss: 1008007.9375\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1282993.3750 - val_loss: 1576393.6250\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1352455.1250 - val_loss: 1030270.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 964631.5625 - val_loss: 1164745.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 903480.7500 - val_loss: 1133611.3750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 908203.5000 - val_loss: 1031035.8125\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1345167.5000 - val_loss: 1004176.5625\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1124612.3750 - val_loss: 1531170.5000\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 880852.1250 - val_loss: 675948.8125\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 779671.0000 - val_loss: 709296.7500\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 804636.1250 - val_loss: 1410653.6250\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 812839.1250 - val_loss: 930215.8125\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 871392.2500 - val_loss: 790649.1875\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 908898.5000 - val_loss: 1560606.0000\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 748010.0625 - val_loss: 1634752.7500\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1092409.7500 - val_loss: 1478400.2500\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1001619.1250 - val_loss: 1085488.8750\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 745527.5625 - val_loss: 606444.8750\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 755027.6250 - val_loss: 566067.1250\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 675801.0000 - val_loss: 906221.4375\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 765595.7500 - val_loss: 725228.1250\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 607357.9375 - val_loss: 1894794.6250\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 746018.3125 - val_loss: 500912.7812\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 501954.8125 - val_loss: 655586.7500\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 564940.9375 - val_loss: 1111528.0000\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 591767.0000 - val_loss: 1507815.2500\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 633479.8750 - val_loss: 474364.5312\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 695639.7500 - val_loss: 986861.4375\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 572576.2500 - val_loss: 563342.8750\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 414027.4062 - val_loss: 500341.1250\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 465054.6562 - val_loss: 850535.3750\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 380499.7500 - val_loss: 333919.0000\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 484335.3438 - val_loss: 592849.7500\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 376537.5625 - val_loss: 812429.8125\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 373337.7188 - val_loss: 438305.0000\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 436567.5938 - val_loss: 582061.0000\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 321138.9375 - val_loss: 474665.8125\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 411194.8750 - val_loss: 775312.6250\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 325796.6875 - val_loss: 421878.3438\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 406096.5625 - val_loss: 238460.8594\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 281323.5000 - val_loss: 285297.1562\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 233039.0312 - val_loss: 237334.4844\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 285239.4375 - val_loss: 219846.6719\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 290108.2188 - val_loss: 252282.3438\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 199917.5625 - val_loss: 406485.7500\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 250679.3594 - val_loss: 211229.7031\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 173645.0781 - val_loss: 162990.6562\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 167155.7969 - val_loss: 210235.1094\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195053.5625 - val_loss: 210648.4844\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 154804.1562 - val_loss: 191337.6875\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 234101.5156 - val_loss: 297720.6562\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 194415.7344 - val_loss: 238548.7500\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 167076.7031 - val_loss: 170021.6250\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 187943.0312 - val_loss: 220552.3750\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 165927.0938 - val_loss: 142537.7344\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131057.4688 - val_loss: 87383.8281\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 151322.9531 - val_loss: 220625.8438\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 138469.7344 - val_loss: 165219.3125\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128152.4141 - val_loss: 111521.4531\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 256059.0156 - val_loss: 87706.6719\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 168823.4531 - val_loss: 538621.5625\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 226954.8281 - val_loss: 251619.0938\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 152117.1719 - val_loss: 64352.3047\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 205617.3438 - val_loss: 201504.6719\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134228.9688 - val_loss: 81650.7891\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 86616.2656 - val_loss: 193747.3125\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 89446.2891 - val_loss: 107819.7578\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 90591168.0000 - val_loss: 37381844.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 29725944.0000 - val_loss: 24431250.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 19999054.0000 - val_loss: 18405724.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 15889587.0000 - val_loss: 14988779.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12056642.0000 - val_loss: 11801174.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9270741.0000 - val_loss: 11082715.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8022610.5000 - val_loss: 15368095.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9242325.0000 - val_loss: 8664489.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6246629.0000 - val_loss: 8842663.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6161918.5000 - val_loss: 7158053.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4926128.0000 - val_loss: 7323161.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6246988.0000 - val_loss: 5822645.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4265616.5000 - val_loss: 4178121.7500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3882840.2500 - val_loss: 4406619.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3290163.2500 - val_loss: 3979887.7500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3534356.2500 - val_loss: 3302245.7500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3411730.5000 - val_loss: 3614442.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2869708.5000 - val_loss: 2756200.7500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2993385.0000 - val_loss: 5008081.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3397258.0000 - val_loss: 2759584.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2730565.0000 - val_loss: 3200586.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3149887.2500 - val_loss: 3950531.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2811061.5000 - val_loss: 2775459.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2540198.2500 - val_loss: 2856497.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2045267.7500 - val_loss: 3661700.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1839551.2500 - val_loss: 2047823.8750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2167811.0000 - val_loss: 1991206.3750\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2125977.2500 - val_loss: 2700597.2500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1875245.6250 - val_loss: 1746851.1250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1419528.2500 - val_loss: 2905042.5000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1542323.0000 - val_loss: 3252535.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1639682.7500 - val_loss: 2064375.6250\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1435419.6250 - val_loss: 1428989.6250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1772504.2500 - val_loss: 2294410.0000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2527764.2500 - val_loss: 1676961.8750\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1533762.3750 - val_loss: 1184912.7500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1290023.3750 - val_loss: 1267422.8750\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1170759.6250 - val_loss: 1899529.5000\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1685718.7500 - val_loss: 2374394.7500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1330226.2500 - val_loss: 1188776.6250\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1044591.8125 - val_loss: 1934130.3750\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1177127.7500 - val_loss: 1127886.6250\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1082411.3750 - val_loss: 1078674.8750\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1124864.5000 - val_loss: 1158122.7500\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1228492.6250 - val_loss: 1164730.6250\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1003363.3125 - val_loss: 1349731.7500\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1141014.5000 - val_loss: 936257.1250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 924409.0625 - val_loss: 845218.5625\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1022742.3750 - val_loss: 1648162.3750\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 981519.2500 - val_loss: 888002.9375\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1084926.5000 - val_loss: 900603.8750\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 966956.8750 - val_loss: 1531931.3750\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 862305.1875 - val_loss: 953168.0000\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 822972.3750 - val_loss: 810624.6875\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 936103.6250 - val_loss: 762974.6875\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 785073.1875 - val_loss: 1242889.0000\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 624965.5625 - val_loss: 504336.1250\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 540154.9375 - val_loss: 810952.1875\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 681517.6875 - val_loss: 707341.6875\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 610027.3125 - val_loss: 883136.0000\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 535050.4375 - val_loss: 512256.5625\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 405166.2188 - val_loss: 528280.4375\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 527537.5000 - val_loss: 456537.4688\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 512138.2500 - val_loss: 384799.2812\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 338974.9062 - val_loss: 385964.9688\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 336611.7500 - val_loss: 698669.1250\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 315996.0625 - val_loss: 396593.5312\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 272558.3125 - val_loss: 310587.6562\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 240142.8594 - val_loss: 400588.2188\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 245803.9062 - val_loss: 265516.8125\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 212878.7344 - val_loss: 172295.0625\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 220765.8125 - val_loss: 425954.6875\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 232285.3906 - val_loss: 267052.8125\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 238286.4531 - val_loss: 395036.5938\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 207406.6562 - val_loss: 220463.7500\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 177180.8281 - val_loss: 218503.1094\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 190824.8906 - val_loss: 126193.0312\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 166760.2344 - val_loss: 129065.2812\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195762.1250 - val_loss: 223431.0312\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 150477.0000 - val_loss: 143751.4844\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 185446.6719 - val_loss: 182967.9844\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 173218.3750 - val_loss: 119553.3203\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 149499.7344 - val_loss: 137527.4688\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 145652.6875 - val_loss: 325364.6250\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 154630.2812 - val_loss: 102996.7578\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 176475.8125 - val_loss: 220764.3906\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195521.2656 - val_loss: 94050.6328\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137411.8125 - val_loss: 86514.8359\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122761.6094 - val_loss: 43878.5781\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133452.3438 - val_loss: 114489.2422\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134150.4375 - val_loss: 121829.5703\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 228311.4531 - val_loss: 388692.5312\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 120559.6953 - val_loss: 118650.0859\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 119661.6875 - val_loss: 105240.6641\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 178598.7031 - val_loss: 130470.5547\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 83070.0156 - val_loss: 181188.1719\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 106930.8359 - val_loss: 232861.8750\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 99243.7422 - val_loss: 56396.9961\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 100166.5312 - val_loss: 178184.2188\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 142.5020 - val_loss: 138.9820\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.8853 - val_loss: 139.8024\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.6041 - val_loss: 135.2613\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.5536 - val_loss: 132.5203\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.9731 - val_loss: 135.4741\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.9754 - val_loss: 134.5354\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.3018 - val_loss: 136.0928\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.3864 - val_loss: 134.9745\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.2556 - val_loss: 133.9709\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.6333 - val_loss: 132.9799\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4236 - val_loss: 131.5151\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.5541 - val_loss: 134.9843\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.0413 - val_loss: 131.8170\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.5944 - val_loss: 130.6979\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.0813 - val_loss: 132.4713\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.6041 - val_loss: 131.5662\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9669 - val_loss: 133.2887\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2037 - val_loss: 132.4804\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6442 - val_loss: 131.9720\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8801 - val_loss: 132.6671\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.1256 - val_loss: 131.3737\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6872 - val_loss: 131.3433\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5110 - val_loss: 129.8306\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4349 - val_loss: 131.4876\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9337 - val_loss: 130.3268\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3176 - val_loss: 129.1472\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6406 - val_loss: 129.1893\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.6173 - val_loss: 129.2795\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.4305 - val_loss: 128.8021\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7278 - val_loss: 130.6207\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.0725 - val_loss: 130.8629\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7287 - val_loss: 129.8737\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0041 - val_loss: 129.6699\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.2890 - val_loss: 131.2398\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.7180 - val_loss: 131.6999\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.1310 - val_loss: 132.7861\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4303 - val_loss: 130.8460\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5662 - val_loss: 128.6774\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.0742 - val_loss: 129.6951\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5930 - val_loss: 129.8030\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.8772 - val_loss: 128.0740\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.7340 - val_loss: 129.4728\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.9554 - val_loss: 130.8148\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.0059 - val_loss: 131.7635\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.1535 - val_loss: 129.2322\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.1246 - val_loss: 129.1955\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 120.9662 - val_loss: 129.5210\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.0100 - val_loss: 131.9429\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 120.7543 - val_loss: 130.1835\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.0218 - val_loss: 129.0835\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 120.8272 - val_loss: 131.1863\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 155.1121 - val_loss: 140.5334\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134.2854 - val_loss: 135.1839\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.1553 - val_loss: 134.0791\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.0673 - val_loss: 137.4837\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.9244 - val_loss: 133.8809\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.6025 - val_loss: 132.1402\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.0476 - val_loss: 136.1398\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.9344 - val_loss: 134.3734\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.1073 - val_loss: 132.4549\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.3419 - val_loss: 132.5238\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.8642 - val_loss: 135.2536\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.7312 - val_loss: 133.2274\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.7840 - val_loss: 132.0821\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.7008 - val_loss: 132.9404\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4335 - val_loss: 131.5992\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5714 - val_loss: 130.6132\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.5573 - val_loss: 129.9884\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8379 - val_loss: 130.2959\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3133 - val_loss: 130.0524\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1568 - val_loss: 130.6745\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8399 - val_loss: 130.4074\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3366 - val_loss: 130.1178\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6143 - val_loss: 130.4356\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1095 - val_loss: 132.1594\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7946 - val_loss: 130.5416\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.2777 - val_loss: 132.2940\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6308 - val_loss: 130.3647\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 146.0610 - val_loss: 143.5744\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.9476 - val_loss: 139.2606\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.2655 - val_loss: 139.4212\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 135.8978 - val_loss: 139.2881\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.5120 - val_loss: 134.5111\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.7775 - val_loss: 133.2583\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.8879 - val_loss: 132.7429\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.5269 - val_loss: 134.7337\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.8807 - val_loss: 132.8347\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.3042 - val_loss: 133.8510\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.6660 - val_loss: 133.4978\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.0652 - val_loss: 132.9042\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.7294 - val_loss: 133.6071\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.7231 - val_loss: 130.9315\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.3851 - val_loss: 133.8260\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1720 - val_loss: 132.2937\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4784 - val_loss: 132.3985\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9603 - val_loss: 130.5261\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4239 - val_loss: 131.9558\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4962 - val_loss: 131.3944\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3246 - val_loss: 130.6295\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7601 - val_loss: 131.5784\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.2958 - val_loss: 129.8667\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4728 - val_loss: 130.9561\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5121 - val_loss: 130.3004\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0978 - val_loss: 130.2855\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5515 - val_loss: 129.8256\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7117 - val_loss: 133.0144\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8033 - val_loss: 131.8814\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5495 - val_loss: 133.2045\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5192 - val_loss: 128.4421\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0362 - val_loss: 130.9569\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8892 - val_loss: 130.6523\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8250 - val_loss: 134.3423\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.1925 - val_loss: 129.1894\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.6815 - val_loss: 130.6303\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.4456 - val_loss: 130.5352\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.4575 - val_loss: 130.1407\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.9341 - val_loss: 131.2332\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.8717 - val_loss: 129.5992\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.4987 - val_loss: 131.6802\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 142.6622 - val_loss: 144.9901\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 138.7489 - val_loss: 136.6287\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.0077 - val_loss: 138.1894\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.9680 - val_loss: 135.9086\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.6694 - val_loss: 134.0302\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.6725 - val_loss: 133.5826\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.0560 - val_loss: 132.5927\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.5366 - val_loss: 130.7865\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.3023 - val_loss: 131.6172\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.3842 - val_loss: 133.8218\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.8134 - val_loss: 133.7364\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8768 - val_loss: 132.4364\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6151 - val_loss: 132.1255\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.7704 - val_loss: 134.2016\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.2784 - val_loss: 129.9650\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9487 - val_loss: 132.3276\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1939 - val_loss: 133.3795\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.7230 - val_loss: 129.5962\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.2532 - val_loss: 128.0481\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4623 - val_loss: 131.4689\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2826 - val_loss: 129.9681\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3210 - val_loss: 130.7750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.9826 - val_loss: 131.0497\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2543 - val_loss: 131.1256\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5864 - val_loss: 129.8897\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8340 - val_loss: 130.2878\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9228 - val_loss: 131.5159\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3699 - val_loss: 129.7932\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4208 - val_loss: 132.1599\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 140.1319 - val_loss: 143.7516\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 135.8618 - val_loss: 138.5716\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.6643 - val_loss: 135.5487\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.3816 - val_loss: 136.1265\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.2648 - val_loss: 135.5455\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.1977 - val_loss: 135.2999\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.6560 - val_loss: 132.1163\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.4659 - val_loss: 134.0294\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.9547 - val_loss: 137.1783\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.2724 - val_loss: 133.2296\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.1993 - val_loss: 131.4277\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.1181 - val_loss: 132.8772\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4420 - val_loss: 134.6164\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1326 - val_loss: 130.1870\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.0977 - val_loss: 131.1940\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.9252 - val_loss: 130.2542\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2297 - val_loss: 132.4835\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.0439 - val_loss: 129.9248\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9229 - val_loss: 131.8413\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6492 - val_loss: 133.1539\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5808 - val_loss: 129.7644\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3015 - val_loss: 129.0112\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7664 - val_loss: 130.1394\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.1093 - val_loss: 130.2037\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8207 - val_loss: 129.3447\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8668 - val_loss: 130.0439\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1140 - val_loss: 131.8126\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8536 - val_loss: 130.1347\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0935 - val_loss: 130.7700\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3205 - val_loss: 131.1368\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.1608 - val_loss: 130.1539\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.2729 - val_loss: 131.2436\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 143.1754 - val_loss: 140.3856\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.6242 - val_loss: 138.4947\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.0727 - val_loss: 136.3660\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.4832 - val_loss: 135.0767\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.0570 - val_loss: 133.6136\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.2645 - val_loss: 137.4021\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 135.6776 - val_loss: 135.4084\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.2480 - val_loss: 135.1693\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.8850 - val_loss: 133.4824\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.7183 - val_loss: 132.1370\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.2263 - val_loss: 132.3268\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.1020 - val_loss: 136.2818\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.4814 - val_loss: 133.2516\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.9819 - val_loss: 133.5579\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.6448 - val_loss: 135.2252\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.6306 - val_loss: 133.6545\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4589 - val_loss: 133.7415\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9803 - val_loss: 133.7374\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9708 - val_loss: 130.8910\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.0728 - val_loss: 130.5541\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.4698 - val_loss: 131.9052\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4542 - val_loss: 131.2928\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.5330 - val_loss: 132.5350\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2316 - val_loss: 130.1373\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2416 - val_loss: 131.2751\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.1799 - val_loss: 131.7229\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3983 - val_loss: 132.1129\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3559 - val_loss: 130.4648\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4782 - val_loss: 130.3690\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6748 - val_loss: 131.9636\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6932 - val_loss: 130.3833\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.1801 - val_loss: 129.8832\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.1029 - val_loss: 130.8582\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5978 - val_loss: 129.4700\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.6115 - val_loss: 130.4990\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7867 - val_loss: 130.2885\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5854 - val_loss: 130.0944\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3710 - val_loss: 130.0485\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9223 - val_loss: 130.4710\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3779 - val_loss: 128.6902\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0217 - val_loss: 131.8567\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5333 - val_loss: 130.3947\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5822 - val_loss: 130.0137\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5434 - val_loss: 129.8062\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.1194 - val_loss: 130.0909\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7384 - val_loss: 129.0466\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.4951 - val_loss: 132.2742\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.3544 - val_loss: 129.2104\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.2188 - val_loss: 130.0416\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.9184 - val_loss: 128.0882\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.9474 - val_loss: 130.3630\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.2530 - val_loss: 127.9843\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.3651 - val_loss: 130.5197\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.0856 - val_loss: 128.8192\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.2089 - val_loss: 127.2055\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.1463 - val_loss: 130.0706\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.8363 - val_loss: 128.6421\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.0159 - val_loss: 129.5751\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.2401 - val_loss: 130.4943\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.1228 - val_loss: 131.9893\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.6243 - val_loss: 129.6356\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.0571 - val_loss: 128.9324\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 120.8985 - val_loss: 129.1761\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.5181 - val_loss: 128.4871\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 120.7221 - val_loss: 129.3995\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 142.3578 - val_loss: 143.7071\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 138.3226 - val_loss: 136.3082\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 136.2460 - val_loss: 141.4812\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.0598 - val_loss: 138.1082\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.3074 - val_loss: 136.8717\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.7865 - val_loss: 135.4770\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.8358 - val_loss: 136.9047\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.4677 - val_loss: 135.2827\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.5253 - val_loss: 137.5582\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.2075 - val_loss: 134.4709\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.5291 - val_loss: 134.1662\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.0418 - val_loss: 135.5294\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1976 - val_loss: 136.4582\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.4531 - val_loss: 132.1874\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.6108 - val_loss: 131.6289\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.3325 - val_loss: 132.3153\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5959 - val_loss: 132.3384\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8521 - val_loss: 130.5457\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.5469 - val_loss: 143.8180\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.3712 - val_loss: 137.2848\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.1755 - val_loss: 132.9058\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2978 - val_loss: 130.7347\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.9439 - val_loss: 130.1991\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8645 - val_loss: 130.8787\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.7194 - val_loss: 131.2333\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4679 - val_loss: 130.9238\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2265 - val_loss: 132.9310\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9271 - val_loss: 133.1404\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2742 - val_loss: 128.6521\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4979 - val_loss: 129.6876\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.0614 - val_loss: 128.7561\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3067 - val_loss: 129.0533\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.2403 - val_loss: 128.3782\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.9489 - val_loss: 129.5967\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.6070 - val_loss: 128.5238\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.2944 - val_loss: 129.0867\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8015 - val_loss: 129.6868\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.8956 - val_loss: 129.2696\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.1717 - val_loss: 128.4880\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.1338 - val_loss: 129.7559\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7340 - val_loss: 129.8079\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.3698 - val_loss: 129.8049\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.7185 - val_loss: 133.1344\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 144.4924 - val_loss: 138.8718\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.2833 - val_loss: 136.5025\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.8862 - val_loss: 137.3302\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.4747 - val_loss: 137.5470\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 135.6064 - val_loss: 134.0511\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.5871 - val_loss: 135.8045\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.9086 - val_loss: 134.3927\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.8156 - val_loss: 133.3834\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.5589 - val_loss: 133.4132\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.8258 - val_loss: 136.2934\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.6017 - val_loss: 135.1719\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.0845 - val_loss: 130.6987\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.1434 - val_loss: 132.2300\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.0832 - val_loss: 131.0648\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2975 - val_loss: 130.9373\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.8113 - val_loss: 131.5742\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.2332 - val_loss: 132.6777\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.3564 - val_loss: 131.4191\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6223 - val_loss: 132.5960\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4646 - val_loss: 131.4245\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2252 - val_loss: 130.5237\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.7671 - val_loss: 130.8121\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4878 - val_loss: 131.5202\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.7831 - val_loss: 130.5668\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.3828 - val_loss: 129.7513\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9810 - val_loss: 130.5740\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9903 - val_loss: 131.2909\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7480 - val_loss: 130.8018\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7625 - val_loss: 131.7374\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.0539 - val_loss: 129.2744\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.9479 - val_loss: 130.2815\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.7039 - val_loss: 130.6618\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5287 - val_loss: 130.1382\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5369 - val_loss: 131.2080\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.6566 - val_loss: 130.0517\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5328 - val_loss: 130.3380\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.0677 - val_loss: 129.9154\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.4743 - val_loss: 130.0369\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.4540 - val_loss: 131.1891\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.2463 - val_loss: 129.5813\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 144.3687 - val_loss: 145.9230\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 142.1084 - val_loss: 144.5633\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 141.1530 - val_loss: 139.6183\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.8875 - val_loss: 141.1006\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.3699 - val_loss: 134.6795\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.9355 - val_loss: 140.1748\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.2950 - val_loss: 134.1547\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.7283 - val_loss: 132.8118\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.4987 - val_loss: 138.5411\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.6401 - val_loss: 134.4991\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.9302 - val_loss: 131.7363\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.2422 - val_loss: 132.4103\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.3214 - val_loss: 131.9835\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.2679 - val_loss: 132.5853\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.8836 - val_loss: 132.9869\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.1438 - val_loss: 132.7202\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.8214 - val_loss: 131.4102\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4266 - val_loss: 132.2299\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1123 - val_loss: 131.9125\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1338 - val_loss: 131.4107\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8764 - val_loss: 129.3481\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8095 - val_loss: 130.6938\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.3545 - val_loss: 132.7793\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.0456 - val_loss: 128.8716\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1283 - val_loss: 129.9829\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5281 - val_loss: 131.8779\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4580 - val_loss: 129.7453\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7022 - val_loss: 130.3236\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4892 - val_loss: 130.1478\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8774 - val_loss: 132.4160\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4927 - val_loss: 129.8931\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.7464 - val_loss: 130.5098\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.6949 - val_loss: 128.9387\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3817 - val_loss: 130.4593\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 157.2089 - val_loss: 148.1604\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.5167 - val_loss: 137.4849\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.2478 - val_loss: 135.4977\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.3782 - val_loss: 137.0686\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.2699 - val_loss: 136.6685\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.7309 - val_loss: 137.3857\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.4678 - val_loss: 134.6476\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.6374 - val_loss: 132.2322\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.0091 - val_loss: 133.0792\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.9426 - val_loss: 135.8372\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.8562 - val_loss: 131.5455\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.2459 - val_loss: 132.6530\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8585 - val_loss: 132.0321\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9101 - val_loss: 131.9937\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1720 - val_loss: 131.9816\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.2634 - val_loss: 131.5307\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4375 - val_loss: 130.1385\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.6001 - val_loss: 131.0439\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6336 - val_loss: 131.8661\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5510 - val_loss: 134.4972\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7907 - val_loss: 128.8323\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8505 - val_loss: 132.3215\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6158 - val_loss: 131.4279\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9359 - val_loss: 129.9365\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1748 - val_loss: 131.0134\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.6242 - val_loss: 129.8987\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.0727 - val_loss: 130.7942\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.3988 - val_loss: 132.8717\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8469 - val_loss: 130.5665\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5046 - val_loss: 131.1710\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.6267 - val_loss: 130.8715\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),100,10,8,0.001)\n",
    "mape_models = train_bagging_models(model_num,'mape',100,10,8,0.001)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),100,10,8,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c961ec8-129c-4f36-a2dc-04b0b9661a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 981us/step\n",
      "12/12 [==============================] - 0s 930us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 946us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 976us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 986us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 1s 770us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 980us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2111923711558894, 0.23659978859903)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat_I = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred_I = np.median(concat_I,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred_I.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_I.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02005ee4-9b13-4a5a-a2c3-d25441395630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred_I.reshape(-1,24)).to_csv(\"../result5_new/NBEATs/pred_mid_I.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat_I[i].reshape(-1,24)).to_csv(f\"../result5_new/NBEATs/pred_I{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a104b3-22fb-46e4-855e-ca5e5202a204",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 일반블락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7fa618-a25e-48c5-9544-ca3e091f28ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0639 - val_loss: 0.7521\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8227 - val_loss: 0.6721\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7996 - val_loss: 0.6671\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7829 - val_loss: 0.6676\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7616 - val_loss: 0.6438\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7369 - val_loss: 0.6555\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7348 - val_loss: 0.6462\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7362 - val_loss: 0.6497\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7217 - val_loss: 0.6260\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7113 - val_loss: 0.6569\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7030 - val_loss: 0.6439\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7009 - val_loss: 0.6485\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6775 - val_loss: 0.6483\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6682 - val_loss: 0.6543\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6608 - val_loss: 0.6762\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6568 - val_loss: 0.6475\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6258 - val_loss: 0.6332\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6084 - val_loss: 0.6854\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6006 - val_loss: 0.7203\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0355 - val_loss: 0.7530\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8367 - val_loss: 0.6883\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8031 - val_loss: 0.6817\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7666 - val_loss: 0.6482\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7654 - val_loss: 0.6556\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7540 - val_loss: 0.6484\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7410 - val_loss: 0.6402\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7396 - val_loss: 0.6402\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7232 - val_loss: 0.6577\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7068 - val_loss: 0.6322\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6964 - val_loss: 0.6576\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6884 - val_loss: 0.6461\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6650 - val_loss: 0.6472\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6910 - val_loss: 0.6605\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6687\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6393 - val_loss: 0.6541\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6168 - val_loss: 0.6548\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6112 - val_loss: 0.6867\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5964 - val_loss: 0.6762\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5955 - val_loss: 0.6486\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 1.0651 - val_loss: 0.7170\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8430 - val_loss: 0.6953\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7899 - val_loss: 0.6878\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7863 - val_loss: 0.6595\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.6375\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7480 - val_loss: 0.6179\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7343 - val_loss: 0.6510\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7173 - val_loss: 0.6330\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7271 - val_loss: 0.6341\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7062 - val_loss: 0.6404\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6901 - val_loss: 0.6334\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6872 - val_loss: 0.6434\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6696 - val_loss: 0.6617\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6536 - val_loss: 0.6422\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6504 - val_loss: 0.6481\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6308 - val_loss: 0.6407\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0589 - val_loss: 0.7595\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8335 - val_loss: 0.7103\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7950 - val_loss: 0.6873\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7783 - val_loss: 0.6301\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7545 - val_loss: 0.6603\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7346 - val_loss: 0.6217\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7234 - val_loss: 0.6380\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7152 - val_loss: 0.6556\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7128 - val_loss: 0.6464\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6930 - val_loss: 0.6291\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6772 - val_loss: 0.6240\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6564 - val_loss: 0.6415\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6587 - val_loss: 0.6397\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6193 - val_loss: 0.6428\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6314 - val_loss: 0.6483\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0485 - val_loss: 0.7308\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8448 - val_loss: 0.6756\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7965 - val_loss: 0.6564\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7780 - val_loss: 0.6578\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7723 - val_loss: 0.6534\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.6322\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7452 - val_loss: 0.6534\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7376 - val_loss: 0.6319\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7119 - val_loss: 0.6588\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7084 - val_loss: 0.6399\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7008 - val_loss: 0.6256\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6827 - val_loss: 0.6366\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6780 - val_loss: 0.6410\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6637 - val_loss: 0.6523\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6725 - val_loss: 0.6340\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6459 - val_loss: 0.6651\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6384 - val_loss: 0.6466\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6171 - val_loss: 0.6848\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6413 - val_loss: 0.6586\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6101 - val_loss: 0.6695\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6004 - val_loss: 0.6618\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0166 - val_loss: 0.7550\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8393 - val_loss: 0.7126\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8113 - val_loss: 0.6820\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7728 - val_loss: 0.6631\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7655 - val_loss: 0.6675\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7492 - val_loss: 0.6417\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7282 - val_loss: 0.6276\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7316 - val_loss: 0.6397\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7109 - val_loss: 0.6446\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7044 - val_loss: 0.6387\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7025 - val_loss: 0.6998\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7201 - val_loss: 0.6512\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6774 - val_loss: 0.6539\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6808 - val_loss: 0.6554\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6560 - val_loss: 0.6645\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6573 - val_loss: 0.6490\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6180 - val_loss: 0.6623\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0484 - val_loss: 0.7376\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8359 - val_loss: 0.7022\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8044 - val_loss: 0.6696\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7726 - val_loss: 0.6661\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7739 - val_loss: 0.6451\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7516 - val_loss: 0.6386\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7366 - val_loss: 0.6570\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7377 - val_loss: 0.6482\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7290 - val_loss: 0.6448\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7265 - val_loss: 0.6784\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6923 - val_loss: 0.6389\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6988 - val_loss: 0.6789\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6723 - val_loss: 0.6346\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6620 - val_loss: 0.6500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6547 - val_loss: 0.6508\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6613\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6423 - val_loss: 0.6545\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6140 - val_loss: 0.6961\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6317 - val_loss: 0.6703\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5994 - val_loss: 0.7081\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5870 - val_loss: 0.6851\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5520 - val_loss: 0.6507\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5322 - val_loss: 0.6707\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0419 - val_loss: 0.7224\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8227 - val_loss: 0.7103\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8146 - val_loss: 0.6988\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7703 - val_loss: 0.6636\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7537 - val_loss: 0.6612\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7350 - val_loss: 0.6408\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7318 - val_loss: 0.6504\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7241 - val_loss: 0.6551\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7179 - val_loss: 0.6639\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7066 - val_loss: 0.6398\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6945 - val_loss: 0.6550\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6876 - val_loss: 0.6402\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6760 - val_loss: 0.6646\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6573 - val_loss: 0.6754\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6541 - val_loss: 0.6695\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 0.6429\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6220 - val_loss: 0.6723\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5917 - val_loss: 0.6425\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5933 - val_loss: 0.7150\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5964 - val_loss: 0.6536\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0408 - val_loss: 0.7349\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8323 - val_loss: 0.6896\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7963 - val_loss: 0.6628\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7818 - val_loss: 0.7059\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.6615\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7369 - val_loss: 0.6381\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7534 - val_loss: 0.6532\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7206 - val_loss: 0.6337\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7236 - val_loss: 0.6454\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6987 - val_loss: 0.6510\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6946 - val_loss: 0.6565\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6726 - val_loss: 0.6593\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6782 - val_loss: 0.6792\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6519 - val_loss: 0.6563\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6518 - val_loss: 0.6497\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6381 - val_loss: 0.6525\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6047 - val_loss: 0.6598\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5896 - val_loss: 0.6459\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.0495 - val_loss: 0.7089\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8360 - val_loss: 0.6881\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8079 - val_loss: 0.6619\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7724 - val_loss: 0.6577\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7634 - val_loss: 0.6925\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.6519\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7301 - val_loss: 0.6357\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7426 - val_loss: 0.6449\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7101 - val_loss: 0.6553\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7035 - val_loss: 0.6644\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6932 - val_loss: 0.7074\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6835 - val_loss: 0.6545\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6574 - val_loss: 0.7182\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6607 - val_loss: 0.6551\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6566 - val_loss: 0.6540\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6258 - val_loss: 0.6451\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6141 - val_loss: 0.6568\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 43235944.0000 - val_loss: 28136532.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 16723181.0000 - val_loss: 12235771.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9781728.0000 - val_loss: 9258501.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7041511.0000 - val_loss: 6091650.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5552718.0000 - val_loss: 4985202.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4082837.7500 - val_loss: 4102693.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3562528.0000 - val_loss: 3377487.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3044217.2500 - val_loss: 3707639.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2576962.5000 - val_loss: 2342149.7500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2190479.0000 - val_loss: 2146272.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1883405.5000 - val_loss: 2104573.2500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1762868.7500 - val_loss: 1864964.3750\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1495367.8750 - val_loss: 2076074.3750\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1548341.1250 - val_loss: 1790608.2500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1337931.3750 - val_loss: 1622555.3750\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1296514.2500 - val_loss: 1364222.6250\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1207322.0000 - val_loss: 1432709.2500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1112574.8750 - val_loss: 1706244.2500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1071853.8750 - val_loss: 1250663.6250\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1107890.1250 - val_loss: 1285205.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 889773.8125 - val_loss: 1198427.5000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 887827.7500 - val_loss: 1289356.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 835642.9375 - val_loss: 947366.8125\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 728153.4375 - val_loss: 1242134.3750\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 799412.0000 - val_loss: 805232.6250\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 836022.3125 - val_loss: 1053565.6250\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 754664.6875 - val_loss: 1076017.8750\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 789408.1250 - val_loss: 1252948.3750\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 750775.0625 - val_loss: 1021345.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 681585.6875 - val_loss: 833808.6875\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 655516.3750 - val_loss: 914726.6250\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 776413.3125 - val_loss: 904822.1875\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 775547.8125 - val_loss: 1360227.2500\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 705081.4375 - val_loss: 1163019.6250\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 685286.5625 - val_loss: 1184927.5000\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 23ms/step - loss: 49054336.0000 - val_loss: 22275162.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 16943648.0000 - val_loss: 13881732.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10456057.0000 - val_loss: 9017122.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7822737.5000 - val_loss: 6058369.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5901679.0000 - val_loss: 5715584.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4590180.0000 - val_loss: 4138048.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3443429.2500 - val_loss: 3473233.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3228267.7500 - val_loss: 4216591.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2850914.5000 - val_loss: 2758552.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2278922.7500 - val_loss: 2785890.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1956134.2500 - val_loss: 2250152.5000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1690593.6250 - val_loss: 1964024.2500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1620292.0000 - val_loss: 2048559.2500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1455360.6250 - val_loss: 1730492.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1315503.8750 - val_loss: 2045694.2500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1277663.5000 - val_loss: 1897402.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1181522.1250 - val_loss: 2072961.7500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1019899.8750 - val_loss: 1525681.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1030813.2500 - val_loss: 2249677.7500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1007527.5000 - val_loss: 1226203.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 811842.6875 - val_loss: 1056380.6250\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 897472.1875 - val_loss: 979079.6250\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 759165.3125 - val_loss: 1138468.1250\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 836139.3750 - val_loss: 825969.3125\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 610925.2500 - val_loss: 1201699.2500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 828471.4375 - val_loss: 799484.3750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 681281.4375 - val_loss: 1050987.2500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 824222.3125 - val_loss: 1060957.1250\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 693821.3125 - val_loss: 1143308.1250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 858704.2500 - val_loss: 1060046.3750\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 781470.5000 - val_loss: 1114021.8750\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 725558.0000 - val_loss: 1246754.2500\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 725140.5625 - val_loss: 821489.5000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 628232.1875 - val_loss: 1025488.3125\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 695483.8750 - val_loss: 1215546.2500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 660387.6875 - val_loss: 1041720.0625\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 44681312.0000 - val_loss: 20446374.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 16809322.0000 - val_loss: 11941742.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9471360.0000 - val_loss: 9295396.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6679637.5000 - val_loss: 6569728.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6515171.0000 - val_loss: 5253909.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4714059.0000 - val_loss: 3902998.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3644196.0000 - val_loss: 3541576.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3047036.2500 - val_loss: 3920422.7500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2777610.7500 - val_loss: 3572114.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2501869.0000 - val_loss: 2102657.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2119624.7500 - val_loss: 2254152.7500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1808356.6250 - val_loss: 2241523.7500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1633805.1250 - val_loss: 1771248.2500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1487452.0000 - val_loss: 1758357.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1340102.2500 - val_loss: 1996074.3750\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1356722.7500 - val_loss: 1355642.8750\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1162645.6250 - val_loss: 1865065.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1149432.1250 - val_loss: 1352917.1250\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1101811.0000 - val_loss: 1542020.7500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1013864.6250 - val_loss: 1008521.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 895589.4375 - val_loss: 1091842.7500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 826402.1875 - val_loss: 1313937.3750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 865209.5625 - val_loss: 1198617.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 816759.5625 - val_loss: 929928.8125\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 777502.0000 - val_loss: 1160332.8750\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 803764.1875 - val_loss: 1177576.0000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 815429.9375 - val_loss: 1001512.9375\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 704413.9375 - val_loss: 1184482.3750\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 746038.4375 - val_loss: 874064.6875\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 687251.1875 - val_loss: 839910.5000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 713420.2500 - val_loss: 916443.9375\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 656145.6875 - val_loss: 1369273.8750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 734220.1875 - val_loss: 838556.9375\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 617777.7500 - val_loss: 827966.5625\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 603720.5625 - val_loss: 987307.1250\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 673029.3750 - val_loss: 958100.5000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 691659.2500 - val_loss: 962933.8750\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 680820.2500 - val_loss: 1170731.6250\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 721900.2500 - val_loss: 1404690.7500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 747020.1875 - val_loss: 956229.8750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 707879.1875 - val_loss: 966241.5625\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 760107.8750 - val_loss: 999213.1250\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 758598.9375 - val_loss: 1647601.6250\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 805669.0625 - val_loss: 1052885.6250\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 50937808.0000 - val_loss: 18990614.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 14664603.0000 - val_loss: 12166646.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10259809.0000 - val_loss: 8372958.5000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6990395.0000 - val_loss: 6495733.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5473542.5000 - val_loss: 5048017.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4246792.0000 - val_loss: 3940891.2500\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3306827.7500 - val_loss: 3474071.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2940344.2500 - val_loss: 2809784.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2490065.0000 - val_loss: 2535424.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1976340.3750 - val_loss: 2267071.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1795473.1250 - val_loss: 2432930.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1699754.2500 - val_loss: 2156720.7500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1514865.1250 - val_loss: 2017546.8750\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1348196.3750 - val_loss: 1896499.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1281431.5000 - val_loss: 1658986.3750\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1185746.7500 - val_loss: 1494948.8750\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1108326.6250 - val_loss: 1351773.6250\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1070040.7500 - val_loss: 1401450.1250\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 984648.7500 - val_loss: 1622588.8750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1061464.0000 - val_loss: 1129671.7500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 975745.4375 - val_loss: 1237665.1250\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 869464.5000 - val_loss: 1430374.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 827833.3125 - val_loss: 1385528.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 920871.9375 - val_loss: 1353823.1250\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 877683.1250 - val_loss: 1205973.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 840083.2500 - val_loss: 1221367.6250\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 797102.7500 - val_loss: 1061135.7500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 761742.9375 - val_loss: 1258906.1250\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 857973.8125 - val_loss: 1049258.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 772259.8750 - val_loss: 1259270.3750\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 750014.8750 - val_loss: 890999.5000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 661790.5625 - val_loss: 982887.3125\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 607719.4375 - val_loss: 868806.6250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 725451.2500 - val_loss: 1085106.3750\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 654662.0625 - val_loss: 861143.3125\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 734867.3125 - val_loss: 837686.4375\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 624211.6250 - val_loss: 790114.5000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 777446.6250 - val_loss: 948579.1875\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 634609.3125 - val_loss: 1094300.7500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 623258.9375 - val_loss: 961493.8750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 584238.3125 - val_loss: 700283.8125\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 618168.6875 - val_loss: 994862.8750\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 623528.3750 - val_loss: 1176486.1250\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 704207.8750 - val_loss: 1066334.2500\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 628986.0000 - val_loss: 695362.3125\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 596370.6875 - val_loss: 1008351.5625\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 627335.8750 - val_loss: 835900.1875\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 580492.8125 - val_loss: 846237.8125\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 658462.2500 - val_loss: 1090956.0000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 603744.8750 - val_loss: 783252.1250\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 653022.0000 - val_loss: 1286072.7500\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 636133.6250 - val_loss: 960538.9375\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 662762.0625 - val_loss: 1048273.7500\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 553188.1250 - val_loss: 961175.1875\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 603891.7500 - val_loss: 936966.6250\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 41797768.0000 - val_loss: 20831884.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 14600099.0000 - val_loss: 10825867.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9660917.0000 - val_loss: 9903835.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7304321.0000 - val_loss: 6823682.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5262659.0000 - val_loss: 5300714.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4089911.2500 - val_loss: 3354431.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3143454.5000 - val_loss: 3438439.7500\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2683504.5000 - val_loss: 2716021.2500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2334862.0000 - val_loss: 2454524.7500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1987822.0000 - val_loss: 2374605.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1960925.6250 - val_loss: 2320959.7500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1719345.0000 - val_loss: 1844716.8750\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1491723.1250 - val_loss: 1667430.7500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1522389.8750 - val_loss: 1849454.8750\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1246246.1250 - val_loss: 1464832.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1298822.8750 - val_loss: 1896702.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1049970.8750 - val_loss: 1616710.1250\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 975463.1875 - val_loss: 1797687.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1053051.2500 - val_loss: 1305671.8750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 916505.0625 - val_loss: 1204950.1250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 802617.8125 - val_loss: 1135650.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 824884.4375 - val_loss: 1138661.2500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 778321.1875 - val_loss: 1335785.6250\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 837700.6250 - val_loss: 1068381.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 801011.9375 - val_loss: 1276974.6250\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 752057.6250 - val_loss: 1050552.0000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 739030.0625 - val_loss: 1240829.7500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 688845.7500 - val_loss: 827664.6875\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 677239.1250 - val_loss: 1422713.6250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 679784.2500 - val_loss: 1184456.8750\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 671408.3750 - val_loss: 800909.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 639327.9375 - val_loss: 843143.3125\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 650652.3750 - val_loss: 1280870.1250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 804781.8125 - val_loss: 918075.5000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 693688.5000 - val_loss: 1079244.1250\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 679132.4375 - val_loss: 1100755.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 670798.0000 - val_loss: 863158.0625\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 724794.1250 - val_loss: 727174.5625\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 629598.1875 - val_loss: 904294.5000\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 639163.1875 - val_loss: 885345.8750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 688369.3125 - val_loss: 891665.9375\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 640260.7500 - val_loss: 816429.4375\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 699132.3125 - val_loss: 1014807.1875\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 660484.1250 - val_loss: 951568.1250\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 693326.3125 - val_loss: 921552.2500\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 696126.5625 - val_loss: 842437.9375\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 669338.9375 - val_loss: 856334.5625\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 616963.0625 - val_loss: 842785.3125\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 44664568.0000 - val_loss: 20797246.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 14765285.0000 - val_loss: 12597067.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10289965.0000 - val_loss: 9401069.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6728438.5000 - val_loss: 5599849.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4914695.0000 - val_loss: 5445155.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4192381.2500 - val_loss: 5571803.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3307135.5000 - val_loss: 3473809.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2880311.2500 - val_loss: 2624582.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2389489.5000 - val_loss: 2686502.2500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2117752.0000 - val_loss: 1976579.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1810938.2500 - val_loss: 2919523.5000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1768162.0000 - val_loss: 1968294.6250\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1471591.7500 - val_loss: 2219167.7500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1416339.7500 - val_loss: 1429872.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1230254.0000 - val_loss: 1632160.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1226061.1250 - val_loss: 2140460.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1097550.5000 - val_loss: 1217833.8750\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 986393.0000 - val_loss: 1752201.8750\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1066472.0000 - val_loss: 1512070.8750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 928100.6250 - val_loss: 1026288.7500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 852028.8750 - val_loss: 1598316.6250\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 924266.6875 - val_loss: 1089184.5000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 780598.3750 - val_loss: 1521281.7500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 906498.9375 - val_loss: 1393608.6250\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 839443.8125 - val_loss: 933812.3125\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 699751.8750 - val_loss: 1088137.2500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 727031.0000 - val_loss: 1032967.1875\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 729466.6875 - val_loss: 1047879.0625\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 689064.8125 - val_loss: 926241.8750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 786894.8750 - val_loss: 1042856.2500\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 673060.3750 - val_loss: 1111264.2500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 645784.0000 - val_loss: 895758.4375\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 582364.5625 - val_loss: 1018492.5625\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 618389.6875 - val_loss: 951434.8125\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 658541.0000 - val_loss: 979746.8750\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 692043.8750 - val_loss: 1158502.1250\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 690565.3125 - val_loss: 1098497.3750\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 591130.6875 - val_loss: 937165.5625\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 621266.8750 - val_loss: 658562.8750\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 729795.6875 - val_loss: 1033883.8125\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 661942.8125 - val_loss: 925580.3125\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 662617.7500 - val_loss: 1297006.6250\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 681353.7500 - val_loss: 998967.3125\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 788991.3750 - val_loss: 898605.5625\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 711867.3750 - val_loss: 661526.0625\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 683924.6250 - val_loss: 913800.6875\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 719928.8125 - val_loss: 1285716.6250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 718634.8750 - val_loss: 959833.1875\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 825688.5000 - val_loss: 1151395.3750\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 51887180.0000 - val_loss: 17910738.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 15765088.0000 - val_loss: 14277814.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10434678.0000 - val_loss: 6731087.5000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7041353.0000 - val_loss: 6691345.5000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5349576.5000 - val_loss: 4144867.7500\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3955671.2500 - val_loss: 3924210.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3271973.7500 - val_loss: 4512156.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2984334.7500 - val_loss: 3913485.7500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2638562.2500 - val_loss: 2328027.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2119578.2500 - val_loss: 2589425.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2000615.0000 - val_loss: 2669843.7500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1674598.0000 - val_loss: 2076626.1250\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1414487.0000 - val_loss: 2039187.2500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1471296.2500 - val_loss: 1906998.7500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1259050.5000 - val_loss: 1774966.6250\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1300937.6250 - val_loss: 1407552.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1087253.2500 - val_loss: 1245157.3750\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1018230.6875 - val_loss: 1672043.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1005949.3125 - val_loss: 1088861.6250\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 920251.2500 - val_loss: 1230636.8750\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 921262.7500 - val_loss: 1279903.3750\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 853156.6250 - val_loss: 1506243.3750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 827292.4375 - val_loss: 1367161.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 894858.3750 - val_loss: 997258.5000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 785789.1250 - val_loss: 1269781.5000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 721420.8125 - val_loss: 1064210.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 736881.2500 - val_loss: 1027226.2500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 783691.3750 - val_loss: 1194375.6250\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 830659.8125 - val_loss: 1092384.3750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 664018.6250 - val_loss: 1131216.5000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 693057.1875 - val_loss: 1085353.8750\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 682853.1875 - val_loss: 1004819.4375\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 690641.8750 - val_loss: 1428410.1250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 770568.5000 - val_loss: 763174.6875\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 586364.3750 - val_loss: 951946.5000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 569164.6875 - val_loss: 856805.8125\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 704753.3125 - val_loss: 861274.3750\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 639763.6250 - val_loss: 565644.6250\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 574527.2500 - val_loss: 770635.2500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 559250.6875 - val_loss: 858733.8750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 682975.0000 - val_loss: 1046095.5625\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 630364.8750 - val_loss: 942602.2500\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 671389.1875 - val_loss: 989574.6250\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 616256.0000 - val_loss: 799555.4375\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 675537.7500 - val_loss: 1111926.3750\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 735921.3750 - val_loss: 1306474.8750\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 613466.3125 - val_loss: 1181003.7500\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 710795.3750 - val_loss: 960556.5625\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 41783416.0000 - val_loss: 19640302.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 13342345.0000 - val_loss: 11745438.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9646268.0000 - val_loss: 8097794.5000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6601637.5000 - val_loss: 6792715.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4954189.5000 - val_loss: 5084549.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3713788.0000 - val_loss: 3712977.7500\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3162499.0000 - val_loss: 3520572.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2759906.7500 - val_loss: 2505699.7500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2346215.5000 - val_loss: 2533878.7500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1828996.8750 - val_loss: 1889241.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1705417.8750 - val_loss: 2025534.6250\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1663031.7500 - val_loss: 1670983.2500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1391295.5000 - val_loss: 1748280.3750\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1286900.0000 - val_loss: 1389362.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1279174.2500 - val_loss: 2030594.6250\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1317675.1250 - val_loss: 1316814.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1195508.7500 - val_loss: 1763771.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1101493.7500 - val_loss: 1481359.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 932777.5000 - val_loss: 1344254.8750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 981256.0000 - val_loss: 1236649.8750\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 818124.7500 - val_loss: 1078409.6250\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 980072.3125 - val_loss: 1254328.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 875310.8750 - val_loss: 1256821.8750\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 827569.0625 - val_loss: 939734.6250\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 730170.8125 - val_loss: 966021.3125\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 741252.3125 - val_loss: 899537.3750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 714107.7500 - val_loss: 950483.8750\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 812485.0625 - val_loss: 1175000.2500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 791559.8750 - val_loss: 880018.0625\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 638987.9375 - val_loss: 1000063.4375\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 728250.7500 - val_loss: 1187990.1250\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 607651.6875 - val_loss: 885085.5625\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 598643.2500 - val_loss: 1151262.2500\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 628225.1875 - val_loss: 788038.2500\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 594696.6875 - val_loss: 699011.3750\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 669164.7500 - val_loss: 1002434.1250\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 802171.0000 - val_loss: 1177305.8750\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 811918.8125 - val_loss: 1221888.3750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 745395.5000 - val_loss: 1005496.0625\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 646538.7500 - val_loss: 1180169.7500\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 699081.0625 - val_loss: 1078772.6250\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 679613.8125 - val_loss: 532908.8750\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 590683.0625 - val_loss: 1032793.6250\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 653276.6875 - val_loss: 897017.0625\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 656688.1250 - val_loss: 838193.6250\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 600345.3125 - val_loss: 765618.1250\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 629876.6250 - val_loss: 992864.8750\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 645160.2500 - val_loss: 660758.8125\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 574261.5000 - val_loss: 1094878.6250\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 636343.9375 - val_loss: 961147.5000\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 610597.7500 - val_loss: 797439.6250\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 715866.7500 - val_loss: 1152003.2500\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 44420876.0000 - val_loss: 27686696.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 18890402.0000 - val_loss: 14996351.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10429098.0000 - val_loss: 8273620.5000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7610546.0000 - val_loss: 6665022.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5567255.5000 - val_loss: 5131539.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4923185.5000 - val_loss: 4682648.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3808548.2500 - val_loss: 3846885.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2887721.7500 - val_loss: 3412063.2500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2888296.0000 - val_loss: 2997396.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2374304.7500 - val_loss: 2426194.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2200886.5000 - val_loss: 2218810.7500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1875196.0000 - val_loss: 2123797.7500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1660764.0000 - val_loss: 1857397.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1636465.8750 - val_loss: 2252202.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1306037.6250 - val_loss: 1623898.3750\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1270445.1250 - val_loss: 1556381.7500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1091149.5000 - val_loss: 1707767.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1239994.8750 - val_loss: 1366487.7500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1122896.5000 - val_loss: 1357308.2500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 972488.0625 - val_loss: 1912569.1250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1065044.8750 - val_loss: 952584.9375\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 914691.6250 - val_loss: 1102500.5000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 869640.1875 - val_loss: 1109192.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 803118.6250 - val_loss: 1692663.0000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 994153.0625 - val_loss: 1052181.2500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 744221.4375 - val_loss: 1124519.3750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 767861.5625 - val_loss: 1073053.1250\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 754628.3125 - val_loss: 963281.7500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 763404.8750 - val_loss: 1482051.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 715644.0625 - val_loss: 978947.0625\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 728045.1250 - val_loss: 909021.7500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 646044.8750 - val_loss: 1046688.0000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 730561.4375 - val_loss: 1052959.5000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 734534.3750 - val_loss: 990430.3750\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 674657.4375 - val_loss: 897862.7500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 619058.6875 - val_loss: 953785.2500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 641618.9375 - val_loss: 754223.8125\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 635048.8750 - val_loss: 1281104.8750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 663358.9375 - val_loss: 883548.8125\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 664114.8125 - val_loss: 884613.4375\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 600967.2500 - val_loss: 994853.7500\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 576151.6250 - val_loss: 925877.8750\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 657233.3125 - val_loss: 792846.4375\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 581714.4375 - val_loss: 812531.5000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 747773.5625 - val_loss: 1110539.8750\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 673585.5625 - val_loss: 1012276.7500\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 658063.2500 - val_loss: 1024318.3750\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 53331080.0000 - val_loss: 22380008.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 15772621.0000 - val_loss: 10312620.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9295067.0000 - val_loss: 7618065.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7342244.0000 - val_loss: 6288243.5000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5178800.5000 - val_loss: 5597351.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4255723.5000 - val_loss: 5131752.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3700138.5000 - val_loss: 3913811.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3304920.7500 - val_loss: 3404871.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2465973.5000 - val_loss: 3273140.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2209705.0000 - val_loss: 2305995.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1951778.5000 - val_loss: 2426582.2500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1805040.5000 - val_loss: 2873817.7500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1684689.0000 - val_loss: 1563590.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1438841.0000 - val_loss: 1626360.2500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1253855.0000 - val_loss: 1662384.7500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1174177.5000 - val_loss: 1532445.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1008010.3125 - val_loss: 1316554.2500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 976681.8750 - val_loss: 1255468.8750\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1007195.0000 - val_loss: 1279584.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1073058.3750 - val_loss: 1439873.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 832503.0625 - val_loss: 1474362.7500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 882211.1250 - val_loss: 1513743.3750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 867957.0625 - val_loss: 966027.3750\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 727995.6875 - val_loss: 1075024.8750\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 878253.4375 - val_loss: 1097394.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 699474.7500 - val_loss: 1392320.3750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 720286.2500 - val_loss: 1023079.3750\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 671263.6250 - val_loss: 1307866.7500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 865259.1250 - val_loss: 1139602.0000\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 769902.0000 - val_loss: 818841.0000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 695913.0625 - val_loss: 1079895.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 678269.6875 - val_loss: 975946.3750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 671496.2500 - val_loss: 1036795.8125\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 651713.0625 - val_loss: 942034.1875\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 596211.1250 - val_loss: 854161.5000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 765088.6250 - val_loss: 1176619.3750\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 573190.3125 - val_loss: 946988.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 778989.2500 - val_loss: 997464.6875\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 833334.6250 - val_loss: 1039959.3750\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 661192.6875 - val_loss: 898307.9375\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 142.8122 - val_loss: 140.4193\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.3227 - val_loss: 139.2910\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.3354 - val_loss: 136.0852\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.0064 - val_loss: 134.0021\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.8329 - val_loss: 133.7092\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.0260 - val_loss: 135.1424\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.4117 - val_loss: 135.3552\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.9256 - val_loss: 131.9017\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.6970 - val_loss: 132.0887\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.9026 - val_loss: 131.4716\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.0913 - val_loss: 131.0284\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.6321 - val_loss: 134.5842\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.0378 - val_loss: 132.7185\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.7635 - val_loss: 131.6887\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.3880 - val_loss: 131.8506\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.2575 - val_loss: 131.0227\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7027 - val_loss: 130.4821\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.9458 - val_loss: 132.8129\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2223 - val_loss: 130.7184\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2901 - val_loss: 130.2931\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2513 - val_loss: 132.6464\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.0277 - val_loss: 131.4880\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.4449 - val_loss: 129.2941\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.8280 - val_loss: 129.7397\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.3308 - val_loss: 130.1094\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.7742 - val_loss: 130.2000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.6505 - val_loss: 130.3451\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.8493 - val_loss: 128.7206\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.6457 - val_loss: 130.8423\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2507 - val_loss: 130.3462\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.7966 - val_loss: 131.3689\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.5819 - val_loss: 129.4981\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.4531 - val_loss: 130.7769\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.4706 - val_loss: 128.6957\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.4625 - val_loss: 131.6059\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.6219 - val_loss: 128.5475\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.9774 - val_loss: 129.5031\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.6036 - val_loss: 130.4079\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.7094 - val_loss: 129.6467\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.3128 - val_loss: 129.6770\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.1841 - val_loss: 129.7067\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.6737 - val_loss: 129.2997\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.5809 - val_loss: 128.1405\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.0866 - val_loss: 128.1265\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.7658 - val_loss: 128.8969\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.4956 - val_loss: 129.2109\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.3310 - val_loss: 128.7269\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.5036 - val_loss: 127.9086\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.7236 - val_loss: 128.5039\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.9986 - val_loss: 130.0440\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.7774 - val_loss: 129.4220\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.1630 - val_loss: 129.8968\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.3017 - val_loss: 129.5272\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.5484 - val_loss: 128.9736\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.2078 - val_loss: 129.0402\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.3086 - val_loss: 130.0477\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.7508 - val_loss: 129.5681\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.8199 - val_loss: 129.3545\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 158.6387 - val_loss: 154.5537\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 153.6756 - val_loss: 153.2454\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 146.6116 - val_loss: 145.2896\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 144.9944 - val_loss: 145.2727\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 145.1672 - val_loss: 148.1693\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 148.4166 - val_loss: 147.3449\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 143.9534 - val_loss: 145.5912\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 143.3357 - val_loss: 146.3711\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 143.7959 - val_loss: 143.3719\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.9601 - val_loss: 146.5061\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 144.1164 - val_loss: 145.5520\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 143.0590 - val_loss: 143.6405\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.2352 - val_loss: 143.9438\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.0771 - val_loss: 141.7528\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 138.3519 - val_loss: 144.3865\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.0624 - val_loss: 137.5636\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.7396 - val_loss: 140.4241\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.9127 - val_loss: 139.3025\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 135.6586 - val_loss: 137.3968\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.1023 - val_loss: 138.0674\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.1378 - val_loss: 137.2955\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.7436 - val_loss: 136.3374\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.8489 - val_loss: 137.0525\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.4685 - val_loss: 135.7426\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.9036 - val_loss: 135.7359\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.6338 - val_loss: 135.3299\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.3310 - val_loss: 137.7299\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.3792 - val_loss: 136.0024\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.6389 - val_loss: 134.3286\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.2645 - val_loss: 136.4595\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.6724 - val_loss: 135.3569\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.4102 - val_loss: 129.5289\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.8845 - val_loss: 128.9007\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.5064 - val_loss: 129.8424\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.9025 - val_loss: 131.6255\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.7980 - val_loss: 128.3927\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.2925 - val_loss: 128.7969\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.1434 - val_loss: 129.2524\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.4532 - val_loss: 128.8959\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.7670 - val_loss: 129.2303\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.8814 - val_loss: 129.8502\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.3786 - val_loss: 128.9636\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.1315 - val_loss: 129.3347\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.5370 - val_loss: 129.2171\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.1644 - val_loss: 130.3092\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.3234 - val_loss: 128.7096\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 146.9097 - val_loss: 139.1173\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 135.5229 - val_loss: 140.3955\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.1374 - val_loss: 135.0734\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.0509 - val_loss: 133.1209\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.7271 - val_loss: 135.4125\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.3020 - val_loss: 132.2549\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.8320 - val_loss: 137.5626\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.2056 - val_loss: 133.4959\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.8385 - val_loss: 134.0997\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.7976 - val_loss: 134.0181\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.0351 - val_loss: 133.6304\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.0594 - val_loss: 133.2118\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.6856 - val_loss: 131.0705\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.8115 - val_loss: 131.0334\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.5879 - val_loss: 129.1373\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.4747 - val_loss: 129.9019\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.9742 - val_loss: 131.7012\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.4091 - val_loss: 131.7609\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.1076 - val_loss: 130.5936\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.3241 - val_loss: 130.3208\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.6996 - val_loss: 130.6616\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.6458 - val_loss: 131.6811\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.0476 - val_loss: 129.5832\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.5515 - val_loss: 130.1232\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.1693 - val_loss: 129.0900\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.7255 - val_loss: 127.8212\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2550 - val_loss: 128.3545\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.7564 - val_loss: 127.8134\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.9275 - val_loss: 130.5783\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.6698 - val_loss: 129.9523\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.9935 - val_loss: 130.0911\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.4042 - val_loss: 130.5602\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.6656 - val_loss: 128.9389\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.7513 - val_loss: 130.1255\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.6719 - val_loss: 129.8068\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.4966 - val_loss: 131.0418\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.5018 - val_loss: 128.9113\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.2902 - val_loss: 128.6139\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 142.4130 - val_loss: 145.2280\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 139.6049 - val_loss: 142.3166\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 141.5363 - val_loss: 143.7356\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 140.8828 - val_loss: 142.3695\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 139.1231 - val_loss: 142.3489\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 143.0842 - val_loss: 141.5350\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 141.1280 - val_loss: 141.3090\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 140.2009 - val_loss: 140.2173\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 138.2001 - val_loss: 138.3829\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.6115 - val_loss: 139.3892\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 139.1397 - val_loss: 138.7101\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.9996 - val_loss: 138.8099\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.1346 - val_loss: 139.5442\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.9492 - val_loss: 139.1885\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.4435 - val_loss: 138.0703\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.0433 - val_loss: 137.8428\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.3962 - val_loss: 138.5700\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 135.8924 - val_loss: 138.3057\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 135.2401 - val_loss: 137.8656\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.5660 - val_loss: 139.3050\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.9885 - val_loss: 137.8228\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.5414 - val_loss: 138.8302\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.2615 - val_loss: 137.8475\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.7707 - val_loss: 138.9338\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.6087 - val_loss: 138.4242\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.6895 - val_loss: 138.3910\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.3087 - val_loss: 137.4482\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.8763 - val_loss: 136.5651\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.8952 - val_loss: 137.7603\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.4919 - val_loss: 134.8771\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.6040 - val_loss: 133.9121\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.0807 - val_loss: 132.1216\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.9577 - val_loss: 132.8335\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.7162 - val_loss: 133.5981\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.4347 - val_loss: 133.2640\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.9825 - val_loss: 133.2142\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.9510 - val_loss: 138.2973\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.2999 - val_loss: 132.7154\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.9498 - val_loss: 131.0090\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.1182 - val_loss: 134.4852\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.3300 - val_loss: 132.1029\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.4857 - val_loss: 132.3038\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.3934 - val_loss: 132.3255\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.4137 - val_loss: 132.2321\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.4560 - val_loss: 133.3586\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.5983 - val_loss: 133.0956\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.7245 - val_loss: 131.6528\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.4037 - val_loss: 131.6174\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.8580 - val_loss: 132.2732\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 147.5892 - val_loss: 146.2219\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 147.3928 - val_loss: 148.2367\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 145.1865 - val_loss: 148.2569\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 144.3692 - val_loss: 145.5320\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.3365 - val_loss: 143.6343\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 141.5691 - val_loss: 143.0650\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.8904 - val_loss: 143.5397\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.5164 - val_loss: 138.8152\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.9854 - val_loss: 137.8058\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.8143 - val_loss: 138.8898\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.6336 - val_loss: 138.7258\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.0770 - val_loss: 137.9498\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.9616 - val_loss: 136.4440\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.9224 - val_loss: 138.2593\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 135.1672 - val_loss: 137.0082\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 135.8444 - val_loss: 137.8150\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.0847 - val_loss: 136.4099\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.6100 - val_loss: 133.7944\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.3025 - val_loss: 136.6518\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.1141 - val_loss: 134.6750\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.3850 - val_loss: 131.9838\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.8941 - val_loss: 134.0968\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.6327 - val_loss: 133.3320\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.6776 - val_loss: 132.5047\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.5135 - val_loss: 131.6327\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.4215 - val_loss: 131.5352\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.7423 - val_loss: 131.2080\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.1130 - val_loss: 131.4417\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.9336 - val_loss: 131.5659\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.4083 - val_loss: 132.0369\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.0866 - val_loss: 131.7505\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.7348 - val_loss: 132.0553\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.5568 - val_loss: 131.4997\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.8001 - val_loss: 131.1212\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.0413 - val_loss: 131.4028\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.4881 - val_loss: 132.2195\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.1030 - val_loss: 131.8047\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.9969 - val_loss: 129.6672\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.3979 - val_loss: 131.1601\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.3629 - val_loss: 131.0137\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.8280 - val_loss: 129.6707\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.1863 - val_loss: 129.7475\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.2491 - val_loss: 129.0224\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.2107 - val_loss: 129.8828\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.3364 - val_loss: 130.2845\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.3305 - val_loss: 128.6135\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.9452 - val_loss: 129.6621\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.8559 - val_loss: 129.5305\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.1148 - val_loss: 129.3086\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.6495 - val_loss: 130.4771\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.2084 - val_loss: 129.8794\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.6557 - val_loss: 129.6406\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.4109 - val_loss: 128.9369\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.3460 - val_loss: 131.6805\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.4796 - val_loss: 129.4613\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.6007 - val_loss: 130.7504\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 150.7823 - val_loss: 146.8352\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 148.3797 - val_loss: 149.1440\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 147.6048 - val_loss: 148.4863\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 145.3855 - val_loss: 147.7143\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 144.1481 - val_loss: 143.5472\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.7191 - val_loss: 146.4704\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.4928 - val_loss: 144.4913\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.2937 - val_loss: 145.2396\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 141.1195 - val_loss: 143.8037\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 141.7606 - val_loss: 144.5848\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 141.2798 - val_loss: 143.8560\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 140.1928 - val_loss: 136.7215\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 135.3858 - val_loss: 138.2045\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.9471 - val_loss: 139.6391\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.4574 - val_loss: 137.3242\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.8819 - val_loss: 138.3367\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.7350 - val_loss: 136.3227\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.6809 - val_loss: 136.5883\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.8847 - val_loss: 135.5064\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.2540 - val_loss: 135.1114\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.7582 - val_loss: 134.2768\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.4253 - val_loss: 136.3900\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.0190 - val_loss: 134.8430\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.7335 - val_loss: 135.8828\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.0931 - val_loss: 134.8028\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.9841 - val_loss: 133.9743\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.8993 - val_loss: 135.0645\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.7850 - val_loss: 133.8113\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.4292 - val_loss: 132.9291\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.9580 - val_loss: 133.8477\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.3060 - val_loss: 134.7461\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.8421 - val_loss: 134.0672\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7223 - val_loss: 133.3527\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.9910 - val_loss: 134.1546\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2321 - val_loss: 135.2332\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2361 - val_loss: 134.3676\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.1694 - val_loss: 134.4096\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.0482 - val_loss: 134.3800\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.8420 - val_loss: 134.4401\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 154.7602 - val_loss: 152.7018\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 148.4099 - val_loss: 149.3475\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 146.4790 - val_loss: 149.5482\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 147.1499 - val_loss: 150.3343\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 146.5533 - val_loss: 150.1522\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 145.4032 - val_loss: 146.6710\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 143.1706 - val_loss: 150.5589\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.1860 - val_loss: 131.6928\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.7794 - val_loss: 132.2830\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.6545 - val_loss: 131.6955\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.2472 - val_loss: 133.4198\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.0290 - val_loss: 130.2180\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.7723 - val_loss: 130.1307\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.6322 - val_loss: 129.1965\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.6067 - val_loss: 130.8641\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.5157 - val_loss: 128.9404\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.3272 - val_loss: 128.9106\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.2417 - val_loss: 129.7410\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7305 - val_loss: 132.7363\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.4291 - val_loss: 131.5284\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.7284 - val_loss: 131.2669\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.7413 - val_loss: 130.0802\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.8071 - val_loss: 128.3824\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.6024 - val_loss: 128.8091\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.6609 - val_loss: 129.2308\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.3556 - val_loss: 128.9558\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.0409 - val_loss: 129.6211\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.8918 - val_loss: 128.1376\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.3271 - val_loss: 129.7670\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.7333 - val_loss: 128.8698\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.3341 - val_loss: 128.5867\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.7641 - val_loss: 129.0573\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.8676 - val_loss: 130.0743\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.7710 - val_loss: 129.3951\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.3140 - val_loss: 129.7569\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.9511 - val_loss: 129.8473\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.8240 - val_loss: 129.4265\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.2035 - val_loss: 130.0198\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 8ms/step - loss: 145.2406 - val_loss: 146.5960\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.9583 - val_loss: 144.1637\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 139.8919 - val_loss: 140.8260\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 140.2871 - val_loss: 141.8570\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.0549 - val_loss: 132.4041\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.9537 - val_loss: 135.1778\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.7311 - val_loss: 130.9330\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.8985 - val_loss: 133.5105\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.3976 - val_loss: 131.5335\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2591 - val_loss: 131.7792\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.2409 - val_loss: 131.1310\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.9172 - val_loss: 132.2303\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.4849 - val_loss: 129.9434\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.1016 - val_loss: 128.9606\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.6214 - val_loss: 129.2806\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.8966 - val_loss: 129.5914\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.9358 - val_loss: 129.2512\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.5504 - val_loss: 128.8302\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.1079 - val_loss: 130.2409\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.7170 - val_loss: 135.0411\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.2685 - val_loss: 128.8636\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.0803 - val_loss: 129.4636\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.7631 - val_loss: 128.7411\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.0927 - val_loss: 128.5709\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.4001 - val_loss: 129.2069\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.8007 - val_loss: 128.1391\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2355 - val_loss: 128.4960\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.4496 - val_loss: 128.1554\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.8490 - val_loss: 129.0280\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.2761 - val_loss: 132.1062\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.5923 - val_loss: 129.0206\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.5868 - val_loss: 128.7809\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.7071 - val_loss: 129.3416\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.1560 - val_loss: 128.5105\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.6364 - val_loss: 129.3785\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.2984 - val_loss: 129.0351\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 153.8944 - val_loss: 151.5959\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 149.2503 - val_loss: 148.2699\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 147.2713 - val_loss: 148.7556\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.4077 - val_loss: 139.0938\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.7452 - val_loss: 138.1482\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.3596 - val_loss: 136.5390\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.1293 - val_loss: 136.2198\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.6675 - val_loss: 133.7266\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.3798 - val_loss: 136.3747\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.1631 - val_loss: 133.0282\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.3488 - val_loss: 133.6616\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.8391 - val_loss: 132.6164\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.2396 - val_loss: 131.3209\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.0095 - val_loss: 131.6293\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.8937 - val_loss: 131.6633\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.2742 - val_loss: 131.4909\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7054 - val_loss: 132.2981\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.2498 - val_loss: 132.7009\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.9765 - val_loss: 130.2906\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.5581 - val_loss: 132.3045\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.8008 - val_loss: 131.4092\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2075 - val_loss: 131.4283\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.1392 - val_loss: 130.9865\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.1011 - val_loss: 131.0812\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.8905 - val_loss: 131.6027\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.0215 - val_loss: 129.6643\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.9696 - val_loss: 131.4259\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.1882 - val_loss: 128.6449\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.6859 - val_loss: 130.2948\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2503 - val_loss: 129.0532\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.5379 - val_loss: 129.0971\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.3548 - val_loss: 129.5523\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.7815 - val_loss: 129.2816\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.8269 - val_loss: 128.4999\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.3801 - val_loss: 129.9442\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.4436 - val_loss: 129.8166\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.5971 - val_loss: 129.5792\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.1382 - val_loss: 130.5705\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.1437 - val_loss: 129.9122\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.9187 - val_loss: 130.4034\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.6512 - val_loss: 128.5689\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.0121 - val_loss: 129.8548\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.0596 - val_loss: 129.3005\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.2621 - val_loss: 128.4402\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.6608 - val_loss: 128.9714\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.9378 - val_loss: 127.8029\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.6589 - val_loss: 129.0250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.8168 - val_loss: 129.0256\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.2400 - val_loss: 128.3679\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.8090 - val_loss: 129.2986\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.8624 - val_loss: 129.6388\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.7583 - val_loss: 129.7418\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.9648 - val_loss: 130.2214\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.5419 - val_loss: 129.4190\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.1318 - val_loss: 128.9865\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.2030 - val_loss: 130.3918\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 150.7644 - val_loss: 147.9725\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 140.3710 - val_loss: 141.3297\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.2901 - val_loss: 133.8856\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.4421 - val_loss: 135.5336\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 135.0764 - val_loss: 134.8274\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.3125 - val_loss: 134.1917\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.6340 - val_loss: 132.4232\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.8375 - val_loss: 133.0277\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.6093 - val_loss: 132.7265\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.2928 - val_loss: 137.7083\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.4444 - val_loss: 133.9426\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.8190 - val_loss: 131.5289\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.6935 - val_loss: 134.9949\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.3291 - val_loss: 130.9680\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.5056 - val_loss: 132.8423\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.6777 - val_loss: 132.8136\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.1174 - val_loss: 131.5394\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7862 - val_loss: 131.7479\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.5994 - val_loss: 131.2022\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7948 - val_loss: 130.8789\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.0984 - val_loss: 132.1058\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.1710 - val_loss: 133.1991\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.3797 - val_loss: 131.7358\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2480 - val_loss: 129.9928\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.1924 - val_loss: 130.4565\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.4708 - val_loss: 130.8971\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.4265 - val_loss: 129.3766\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.8446 - val_loss: 129.1717\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.2268 - val_loss: 130.8736\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2460 - val_loss: 129.6991\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.0973 - val_loss: 130.7228\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.8553 - val_loss: 129.4811\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.8608 - val_loss: 131.0891\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.7474 - val_loss: 128.9572\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.1201 - val_loss: 128.9068\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.4522 - val_loss: 128.9851\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.2559 - val_loss: 128.4339\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.4196 - val_loss: 128.9004\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.5695 - val_loss: 129.0734\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.1183 - val_loss: 130.6398\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.2331 - val_loss: 130.0269\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.8241 - val_loss: 131.2946\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.4291 - val_loss: 129.5588\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.0411 - val_loss: 129.2504\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.3462 - val_loss: 129.1748\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.3834 - val_loss: 129.9225\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.7677 - val_loss: 130.2483\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "mase_models_G = train_bagging_models_G(model_num, MASE(y_train,24),100,10,8,0.001)\n",
    "mape_models_G = train_bagging_models_G(model_num,'mape',100,10,8,0.001)\n",
    "smape_models_G = train_bagging_models_G(model_num, SMAPE(),100,10,8,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8e382f-5a29-464f-abe0-eeee880e371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 2s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20643088546609298, 0.23579850110961875)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models_G\n",
    "pred2,_=mase_models_G\n",
    "pred3,_=mape_models_G\n",
    "\n",
    "smape_predictions_G = bagging_predict2(pred1, test_X)\n",
    "mase_predictions_G = bagging_predict2(pred2, test_X)\n",
    "mape_predictions_G = bagging_predict2(pred3, test_X)\n",
    "concat_G = np.concatenate([smape_predictions_G, mase_predictions_G,mape_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred_G.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e4e0e-fe29-484c-be93-fd2c7ee76e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred_G.reshape(-1,24)).to_csv(\"../result5_new/NBEATs/pred_mid_G.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat_G[i].reshape(-1,24)).to_csv(f\"../result5_new/NBEATs/pred_G{i}.c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
